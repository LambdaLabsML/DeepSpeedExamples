ml-512-node-033 slots=8
ml-512-node-034 slots=8
ml-512-node-035 slots=8
ml-512-node-036 slots=8
ml-512-node-037 slots=8
ml-512-node-038 slots=8
ml-512-node-039 slots=8
ml-512-node-040 slots=8
ml-512-node-041 slots=8
ml-512-node-042 slots=8
ml-512-node-043 slots=8
ml-512-node-044 slots=8
ml-512-node-045 slots=8
ml-512-node-046 slots=8
ml-512-node-047 slots=8
ml-512-node-048 slots=8
[2024-07-08 06:00:36,306] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
2024-07-08 06:00:37.713313: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-07-08 06:00:37.751669: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[2024-07-08 06:00:39,243] [INFO] [runner.py:557:main] deepspeed_env file = ./.deepspeed_env
[2024-07-08 06:00:39,244] [INFO] [multinode_runner.py:81:get_cmd] Running on the following workers: ml-512-node-033,ml-512-node-034,ml-512-node-035,ml-512-node-036,ml-512-node-037,ml-512-node-038,ml-512-node-039,ml-512-node-040,ml-512-node-041,ml-512-node-042,ml-512-node-043,ml-512-node-044,ml-512-node-045,ml-512-node-046,ml-512-node-047,ml-512-node-048
[2024-07-08 06:00:39,244] [INFO] [runner.py:568:main] cmd = pdsh -S -f 1024 -w ml-512-node-033,ml-512-node-034,ml-512-node-035,ml-512-node-036,ml-512-node-037,ml-512-node-038,ml-512-node-039,ml-512-node-040,ml-512-node-041,ml-512-node-042,ml-512-node-043,ml-512-node-044,ml-512-node-045,ml-512-node-046,ml-512-node-047,ml-512-node-048 export PYTHONPATH=/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training; export PROJECT_PATH=/home/ubuntu/ml-1cc/benchmark; export OMPI_MCA_btl_tcp_if_include=eno1; export UCX_TLS=self,shm,tcp; export NCCL_P2P_LEVEL=NVL; export NCCL_NET_GDR_LEVEL=PIX; export NCCL_IB_HCA='=mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8'; export NCCL_IB_PCI_RELAXED_ORDERING=1; export NCCL_SOCKET_IFNAME=eno1; export NCCL_DEBUG=WARN;  cd /home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training; /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJtbC01MTItbm9kZS0wMzMiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMzQiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMzUiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMzYiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMzciOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMzgiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMzkiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDAiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDEiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDIiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDMiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDQiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDUiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDYiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDciOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDgiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --node_rank=%n --master_addr=ml-512-node-033 --master_port=29500 /home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py --data_path Dahoas/full-hh-rlhf --data_split 2,4,4 --data_output_path /home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1 --model_name_or_path facebook/opt-350m --per_device_train_batch_size 24 --per_device_eval_batch_size 4 --max_seq_len 512 --learning_rate 1e-10 --weight_decay 0.1 --disable_dropout --gradient_accumulation_steps 1 --lr_scheduler_type cosine --seed 1234 --zero_stage 0 --deepspeed --num_warmup_steps 10 --num_train_epochs 100 --max_steps 100
ml-512-node-033: [2024-07-08 06:00:40,648] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-033: 2024-07-08 06:00:42.060442: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-033: 2024-07-08 06:00:42.098242: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-033: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-037: [2024-07-08 06:00:42,839] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [2024-07-08 06:00:42,867] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [2024-07-08 06:00:42,878] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [2024-07-08 06:00:42,884] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: [2024-07-08 06:00:42,903] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [2024-07-08 06:00:42,908] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-040: [2024-07-08 06:00:43,001] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [2024-07-08 06:00:43,057] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [2024-07-08 06:00:43,067] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [2024-07-08 06:00:43,075] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [2024-07-08 06:00:43,080] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [2024-07-08 06:00:43,082] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [2024-07-08 06:00:43,098] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [2024-07-08 06:00:43,106] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-041: [2024-07-08 06:00:43,115] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [2024-07-08 06:00:43,358] [INFO] [launch.py:139:main] 0 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-033: [2024-07-08 06:00:43,358] [INFO] [launch.py:139:main] 0 NCCL_SOCKET_IFNAME=eno1
ml-512-node-033: [2024-07-08 06:00:43,358] [INFO] [launch.py:139:main] 0 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-033: [2024-07-08 06:00:43,358] [INFO] [launch.py:139:main] 0 NCCL_P2P_LEVEL=NVL
ml-512-node-033: [2024-07-08 06:00:43,358] [INFO] [launch.py:139:main] 0 NCCL_DEBUG=WARN
ml-512-node-033: [2024-07-08 06:00:43,358] [INFO] [launch.py:139:main] 0 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-033: [2024-07-08 06:00:43,358] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-033: [2024-07-08 06:00:43,358] [INFO] [launch.py:152:main] nnodes=16, num_local_procs=8, node_rank=0
ml-512-node-033: [2024-07-08 06:00:43,358] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127]})
ml-512-node-033: [2024-07-08 06:00:43,358] [INFO] [launch.py:164:main] dist_world_size=128
ml-512-node-033: [2024-07-08 06:00:43,358] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [2024-07-08 06:00:43,359] [INFO] [launch.py:256:main] process 1066001 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 06:00:43,360] [INFO] [launch.py:256:main] process 1066002 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 06:00:43,361] [INFO] [launch.py:256:main] process 1066003 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 06:00:43,362] [INFO] [launch.py:256:main] process 1066004 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 06:00:43,362] [INFO] [launch.py:256:main] process 1066005 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 06:00:43,363] [INFO] [launch.py:256:main] process 1066006 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 06:00:43,363] [INFO] [launch.py:256:main] process 1066007 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 06:00:43,364] [INFO] [launch.py:256:main] process 1066008 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: 2024-07-08 06:00:44.180506: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-037: 2024-07-08 06:00:44.218251: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-037: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-036: 2024-07-08 06:00:44.220892: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-038: 2024-07-08 06:00:44.238597: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-039: 2024-07-08 06:00:44.255226: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-036: 2024-07-08 06:00:44.258414: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-036: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-035: 2024-07-08 06:00:44.267834: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-038: 2024-07-08 06:00:44.277278: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-038: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-039: 2024-07-08 06:00:44.292681: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-039: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-035: 2024-07-08 06:00:44.305527: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-035: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-034: 2024-07-08 06:00:44.380523: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-048: 2024-07-08 06:00:44.388606: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-045: 2024-07-08 06:00:44.414122: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-034: 2024-07-08 06:00:44.420187: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-034: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-047: 2024-07-08 06:00:44.422603: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-048: 2024-07-08 06:00:44.427266: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-048: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-043: 2024-07-08 06:00:44.445458: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-045: 2024-07-08 06:00:44.453883: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-045: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-047: 2024-07-08 06:00:44.460206: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-047: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-044: 2024-07-08 06:00:44.465865: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-046: 2024-07-08 06:00:44.468897: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-042: 2024-07-08 06:00:44.469776: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-043: 2024-07-08 06:00:44.485105: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-043: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-044: 2024-07-08 06:00:44.504806: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-044: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-046: 2024-07-08 06:00:44.508031: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-046: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-042: 2024-07-08 06:00:44.509280: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-042: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-041: 2024-07-08 06:00:44.522143: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-041: 2024-07-08 06:00:44.561181: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-041: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-040: 2024-07-08 06:00:44.636639: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-040: 2024-07-08 06:00:44.672661: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-040: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-037: [2024-07-08 06:00:45,507] [INFO] [launch.py:139:main] 4 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-037: [2024-07-08 06:00:45,507] [INFO] [launch.py:139:main] 4 NCCL_SOCKET_IFNAME=eno1
ml-512-node-037: [2024-07-08 06:00:45,507] [INFO] [launch.py:139:main] 4 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-037: [2024-07-08 06:00:45,507] [INFO] [launch.py:139:main] 4 NCCL_P2P_LEVEL=NVL
ml-512-node-037: [2024-07-08 06:00:45,507] [INFO] [launch.py:139:main] 4 NCCL_DEBUG=WARN
ml-512-node-037: [2024-07-08 06:00:45,507] [INFO] [launch.py:139:main] 4 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-037: [2024-07-08 06:00:45,507] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-037: [2024-07-08 06:00:45,507] [INFO] [launch.py:152:main] nnodes=16, num_local_procs=8, node_rank=4
ml-512-node-037: [2024-07-08 06:00:45,507] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127]})
ml-512-node-037: [2024-07-08 06:00:45,507] [INFO] [launch.py:164:main] dist_world_size=128
ml-512-node-037: [2024-07-08 06:00:45,507] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-037: [2024-07-08 06:00:45,508] [INFO] [launch.py:256:main] process 1059852 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 06:00:45,509] [INFO] [launch.py:256:main] process 1059853 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 06:00:45,510] [INFO] [launch.py:256:main] process 1059854 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 06:00:45,510] [INFO] [launch.py:256:main] process 1059855 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 06:00:45,511] [INFO] [launch.py:256:main] process 1059856 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 06:00:45,512] [INFO] [launch.py:256:main] process 1059857 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 06:00:45,512] [INFO] [launch.py:256:main] process 1059858 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 06:00:45,513] [INFO] [launch.py:256:main] process 1059859 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 06:00:45,530] [INFO] [launch.py:139:main] 3 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-036: [2024-07-08 06:00:45,530] [INFO] [launch.py:139:main] 3 NCCL_SOCKET_IFNAME=eno1
ml-512-node-036: [2024-07-08 06:00:45,530] [INFO] [launch.py:139:main] 3 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-036: [2024-07-08 06:00:45,530] [INFO] [launch.py:139:main] 3 NCCL_P2P_LEVEL=NVL
ml-512-node-036: [2024-07-08 06:00:45,530] [INFO] [launch.py:139:main] 3 NCCL_DEBUG=WARN
ml-512-node-036: [2024-07-08 06:00:45,530] [INFO] [launch.py:139:main] 3 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-036: [2024-07-08 06:00:45,530] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-036: [2024-07-08 06:00:45,530] [INFO] [launch.py:152:main] nnodes=16, num_local_procs=8, node_rank=3
ml-512-node-036: [2024-07-08 06:00:45,530] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127]})
ml-512-node-036: [2024-07-08 06:00:45,530] [INFO] [launch.py:164:main] dist_world_size=128
ml-512-node-036: [2024-07-08 06:00:45,530] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-036: [2024-07-08 06:00:45,531] [INFO] [launch.py:256:main] process 1055801 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 06:00:45,532] [INFO] [launch.py:256:main] process 1055802 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 06:00:45,533] [INFO] [launch.py:256:main] process 1055803 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 06:00:45,533] [INFO] [launch.py:256:main] process 1055804 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 06:00:45,534] [INFO] [launch.py:256:main] process 1055805 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 06:00:45,534] [INFO] [launch.py:256:main] process 1055806 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 06:00:45,535] [INFO] [launch.py:256:main] process 1055807 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 06:00:45,536] [INFO] [launch.py:256:main] process 1055808 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 06:00:45,551] [INFO] [launch.py:139:main] 6 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-039: [2024-07-08 06:00:45,551] [INFO] [launch.py:139:main] 6 NCCL_SOCKET_IFNAME=eno1
ml-512-node-039: [2024-07-08 06:00:45,551] [INFO] [launch.py:139:main] 6 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-039: [2024-07-08 06:00:45,551] [INFO] [launch.py:139:main] 6 NCCL_P2P_LEVEL=NVL
ml-512-node-039: [2024-07-08 06:00:45,551] [INFO] [launch.py:139:main] 6 NCCL_DEBUG=WARN
ml-512-node-039: [2024-07-08 06:00:45,551] [INFO] [launch.py:139:main] 6 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-039: [2024-07-08 06:00:45,551] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-039: [2024-07-08 06:00:45,551] [INFO] [launch.py:152:main] nnodes=16, num_local_procs=8, node_rank=6
ml-512-node-039: [2024-07-08 06:00:45,551] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127]})
ml-512-node-039: [2024-07-08 06:00:45,551] [INFO] [launch.py:164:main] dist_world_size=128
ml-512-node-039: [2024-07-08 06:00:45,551] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-039: [2024-07-08 06:00:45,552] [INFO] [launch.py:256:main] process 1142672 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 06:00:45,553] [INFO] [launch.py:256:main] process 1142673 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 06:00:45,553] [INFO] [launch.py:256:main] process 1142674 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 06:00:45,554] [INFO] [launch.py:256:main] process 1142675 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 06:00:45,555] [INFO] [launch.py:256:main] process 1142676 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 06:00:45,555] [INFO] [launch.py:256:main] process 1142677 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 06:00:45,556] [INFO] [launch.py:256:main] process 1142678 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 06:00:45,557] [INFO] [launch.py:256:main] process 1142679 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 06:00:45,568] [INFO] [launch.py:139:main] 5 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-038: [2024-07-08 06:00:45,568] [INFO] [launch.py:139:main] 5 NCCL_SOCKET_IFNAME=eno1
ml-512-node-038: [2024-07-08 06:00:45,568] [INFO] [launch.py:139:main] 5 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-038: [2024-07-08 06:00:45,568] [INFO] [launch.py:139:main] 5 NCCL_P2P_LEVEL=NVL
ml-512-node-038: [2024-07-08 06:00:45,568] [INFO] [launch.py:139:main] 5 NCCL_DEBUG=WARN
ml-512-node-038: [2024-07-08 06:00:45,568] [INFO] [launch.py:139:main] 5 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-038: [2024-07-08 06:00:45,568] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-038: [2024-07-08 06:00:45,568] [INFO] [launch.py:152:main] nnodes=16, num_local_procs=8, node_rank=5
ml-512-node-038: [2024-07-08 06:00:45,569] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127]})
ml-512-node-038: [2024-07-08 06:00:45,569] [INFO] [launch.py:164:main] dist_world_size=128
ml-512-node-038: [2024-07-08 06:00:45,569] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-038: [2024-07-08 06:00:45,569] [INFO] [launch.py:256:main] process 1055363 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 06:00:45,570] [INFO] [launch.py:256:main] process 1055364 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 06:00:45,571] [INFO] [launch.py:256:main] process 1055365 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 06:00:45,572] [INFO] [launch.py:256:main] process 1055366 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 06:00:45,572] [INFO] [launch.py:256:main] process 1055367 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 06:00:45,573] [INFO] [launch.py:256:main] process 1055368 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 06:00:45,574] [INFO] [launch.py:256:main] process 1055369 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 06:00:45,574] [INFO] [launch.py:256:main] process 1055370 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-035: [2024-07-08 06:00:45,600] [INFO] [launch.py:139:main] 2 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-035: [2024-07-08 06:00:45,600] [INFO] [launch.py:139:main] 2 NCCL_SOCKET_IFNAME=eno1
ml-512-node-035: [2024-07-08 06:00:45,600] [INFO] [launch.py:139:main] 2 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-035: [2024-07-08 06:00:45,600] [INFO] [launch.py:139:main] 2 NCCL_P2P_LEVEL=NVL
ml-512-node-035: [2024-07-08 06:00:45,600] [INFO] [launch.py:139:main] 2 NCCL_DEBUG=WARN
ml-512-node-035: [2024-07-08 06:00:45,600] [INFO] [launch.py:139:main] 2 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-035: [2024-07-08 06:00:45,600] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-035: [2024-07-08 06:00:45,600] [INFO] [launch.py:152:main] nnodes=16, num_local_procs=8, node_rank=2
ml-512-node-035: [2024-07-08 06:00:45,600] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127]})
ml-512-node-035: [2024-07-08 06:00:45,601] [INFO] [launch.py:164:main] dist_world_size=128
ml-512-node-035: [2024-07-08 06:00:45,601] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-035: [2024-07-08 06:00:45,601] [INFO] [launch.py:256:main] process 1063311 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-035: [2024-07-08 06:00:45,602] [INFO] [launch.py:256:main] process 1063312 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-035: [2024-07-08 06:00:45,603] [INFO] [launch.py:256:main] process 1063313 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-035: [2024-07-08 06:00:45,604] [INFO] [launch.py:256:main] process 1063314 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-035: [2024-07-08 06:00:45,604] [INFO] [launch.py:256:main] process 1063315 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-035: [2024-07-08 06:00:45,605] [INFO] [launch.py:256:main] process 1063316 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-035: [2024-07-08 06:00:45,606] [INFO] [launch.py:256:main] process 1063317 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-035: [2024-07-08 06:00:45,606] [INFO] [launch.py:256:main] process 1063318 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 06:00:45,692] [INFO] [launch.py:139:main] 15 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-048: [2024-07-08 06:00:45,692] [INFO] [launch.py:139:main] 15 NCCL_SOCKET_IFNAME=eno1
ml-512-node-048: [2024-07-08 06:00:45,692] [INFO] [launch.py:139:main] 15 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-048: [2024-07-08 06:00:45,692] [INFO] [launch.py:139:main] 15 NCCL_P2P_LEVEL=NVL
ml-512-node-048: [2024-07-08 06:00:45,692] [INFO] [launch.py:139:main] 15 NCCL_DEBUG=WARN
ml-512-node-048: [2024-07-08 06:00:45,692] [INFO] [launch.py:139:main] 15 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-048: [2024-07-08 06:00:45,692] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-048: [2024-07-08 06:00:45,692] [INFO] [launch.py:152:main] nnodes=16, num_local_procs=8, node_rank=15
ml-512-node-048: [2024-07-08 06:00:45,692] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127]})
ml-512-node-048: [2024-07-08 06:00:45,692] [INFO] [launch.py:164:main] dist_world_size=128
ml-512-node-048: [2024-07-08 06:00:45,692] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-048: [2024-07-08 06:00:45,693] [INFO] [launch.py:256:main] process 1053103 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 06:00:45,694] [INFO] [launch.py:256:main] process 1053104 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 06:00:45,695] [INFO] [launch.py:256:main] process 1053105 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 06:00:45,695] [INFO] [launch.py:256:main] process 1053106 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 06:00:45,696] [INFO] [launch.py:256:main] process 1053107 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 06:00:45,697] [INFO] [launch.py:256:main] process 1053108 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 06:00:45,697] [INFO] [launch.py:256:main] process 1053109 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 06:00:45,698] [INFO] [launch.py:256:main] process 1053110 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 06:00:45,702] [INFO] [launch.py:139:main] 12 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-045: [2024-07-08 06:00:45,702] [INFO] [launch.py:139:main] 12 NCCL_SOCKET_IFNAME=eno1
ml-512-node-045: [2024-07-08 06:00:45,702] [INFO] [launch.py:139:main] 12 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-045: [2024-07-08 06:00:45,702] [INFO] [launch.py:139:main] 12 NCCL_P2P_LEVEL=NVL
ml-512-node-045: [2024-07-08 06:00:45,702] [INFO] [launch.py:139:main] 12 NCCL_DEBUG=WARN
ml-512-node-045: [2024-07-08 06:00:45,702] [INFO] [launch.py:139:main] 12 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-045: [2024-07-08 06:00:45,702] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-045: [2024-07-08 06:00:45,702] [INFO] [launch.py:152:main] nnodes=16, num_local_procs=8, node_rank=12
ml-512-node-045: [2024-07-08 06:00:45,702] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127]})
ml-512-node-045: [2024-07-08 06:00:45,702] [INFO] [launch.py:164:main] dist_world_size=128
ml-512-node-045: [2024-07-08 06:00:45,702] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-045: [2024-07-08 06:00:45,703] [INFO] [launch.py:256:main] process 1058672 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 06:00:45,704] [INFO] [launch.py:256:main] process 1058673 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 06:00:45,705] [INFO] [launch.py:256:main] process 1058674 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 06:00:45,705] [INFO] [launch.py:256:main] process 1058675 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 06:00:45,706] [INFO] [launch.py:256:main] process 1058676 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 06:00:45,707] [INFO] [launch.py:256:main] process 1058677 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 06:00:45,707] [INFO] [launch.py:256:main] process 1058678 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 06:00:45,708] [INFO] [launch.py:256:main] process 1058679 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-034: [2024-07-08 06:00:45,721] [INFO] [launch.py:139:main] 1 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-034: [2024-07-08 06:00:45,721] [INFO] [launch.py:139:main] 1 NCCL_SOCKET_IFNAME=eno1
ml-512-node-034: [2024-07-08 06:00:45,721] [INFO] [launch.py:139:main] 1 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-034: [2024-07-08 06:00:45,721] [INFO] [launch.py:139:main] 1 NCCL_P2P_LEVEL=NVL
ml-512-node-034: [2024-07-08 06:00:45,721] [INFO] [launch.py:139:main] 1 NCCL_DEBUG=WARN
ml-512-node-034: [2024-07-08 06:00:45,721] [INFO] [launch.py:139:main] 1 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-034: [2024-07-08 06:00:45,721] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-034: [2024-07-08 06:00:45,721] [INFO] [launch.py:152:main] nnodes=16, num_local_procs=8, node_rank=1
ml-512-node-034: [2024-07-08 06:00:45,721] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127]})
ml-512-node-034: [2024-07-08 06:00:45,722] [INFO] [launch.py:164:main] dist_world_size=128
ml-512-node-034: [2024-07-08 06:00:45,722] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-034: [2024-07-08 06:00:45,722] [INFO] [launch.py:256:main] process 1056484 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-034: [2024-07-08 06:00:45,723] [INFO] [launch.py:256:main] process 1056485 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 06:00:45,723] [INFO] [launch.py:139:main] 14 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-047: [2024-07-08 06:00:45,723] [INFO] [launch.py:139:main] 14 NCCL_SOCKET_IFNAME=eno1
ml-512-node-047: [2024-07-08 06:00:45,723] [INFO] [launch.py:139:main] 14 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-047: [2024-07-08 06:00:45,723] [INFO] [launch.py:139:main] 14 NCCL_P2P_LEVEL=NVL
ml-512-node-047: [2024-07-08 06:00:45,723] [INFO] [launch.py:139:main] 14 NCCL_DEBUG=WARN
ml-512-node-047: [2024-07-08 06:00:45,723] [INFO] [launch.py:139:main] 14 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-047: [2024-07-08 06:00:45,723] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-047: [2024-07-08 06:00:45,723] [INFO] [launch.py:152:main] nnodes=16, num_local_procs=8, node_rank=14
ml-512-node-047: [2024-07-08 06:00:45,723] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127]})
ml-512-node-047: [2024-07-08 06:00:45,723] [INFO] [launch.py:164:main] dist_world_size=128
ml-512-node-047: [2024-07-08 06:00:45,723] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-034: [2024-07-08 06:00:45,724] [INFO] [launch.py:256:main] process 1056486 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 06:00:45,724] [INFO] [launch.py:256:main] process 1056879 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-034: [2024-07-08 06:00:45,724] [INFO] [launch.py:256:main] process 1056487 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-034: [2024-07-08 06:00:45,725] [INFO] [launch.py:256:main] process 1056488 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 06:00:45,725] [INFO] [launch.py:256:main] process 1056880 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-034: [2024-07-08 06:00:45,726] [INFO] [launch.py:256:main] process 1056489 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 06:00:45,726] [INFO] [launch.py:256:main] process 1056881 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-034: [2024-07-08 06:00:45,726] [INFO] [launch.py:256:main] process 1056490 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 06:00:45,726] [INFO] [launch.py:256:main] process 1056882 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-034: [2024-07-08 06:00:45,727] [INFO] [launch.py:256:main] process 1056491 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 06:00:45,727] [INFO] [launch.py:256:main] process 1056883 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 06:00:45,727] [INFO] [launch.py:256:main] process 1056884 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 06:00:45,728] [INFO] [launch.py:256:main] process 1056885 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 06:00:45,729] [INFO] [launch.py:256:main] process 1056886 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-043: [2024-07-08 06:00:45,760] [INFO] [launch.py:139:main] 10 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-043: [2024-07-08 06:00:45,760] [INFO] [launch.py:139:main] 10 NCCL_SOCKET_IFNAME=eno1
ml-512-node-043: [2024-07-08 06:00:45,760] [INFO] [launch.py:139:main] 10 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-043: [2024-07-08 06:00:45,760] [INFO] [launch.py:139:main] 10 NCCL_P2P_LEVEL=NVL
ml-512-node-043: [2024-07-08 06:00:45,760] [INFO] [launch.py:139:main] 10 NCCL_DEBUG=WARN
ml-512-node-043: [2024-07-08 06:00:45,760] [INFO] [launch.py:139:main] 10 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-043: [2024-07-08 06:00:45,760] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-043: [2024-07-08 06:00:45,760] [INFO] [launch.py:152:main] nnodes=16, num_local_procs=8, node_rank=10
ml-512-node-043: [2024-07-08 06:00:45,760] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127]})
ml-512-node-043: [2024-07-08 06:00:45,760] [INFO] [launch.py:164:main] dist_world_size=128
ml-512-node-043: [2024-07-08 06:00:45,760] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-043: [2024-07-08 06:00:45,761] [INFO] [launch.py:256:main] process 1058741 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-043: [2024-07-08 06:00:45,761] [INFO] [launch.py:256:main] process 1058742 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-043: [2024-07-08 06:00:45,762] [INFO] [launch.py:256:main] process 1058743 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-043: [2024-07-08 06:00:45,763] [INFO] [launch.py:256:main] process 1058744 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-043: [2024-07-08 06:00:45,764] [INFO] [launch.py:256:main] process 1058745 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-043: [2024-07-08 06:00:45,764] [INFO] [launch.py:256:main] process 1058746 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 06:00:45,763] [INFO] [launch.py:139:main] 9 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-042: [2024-07-08 06:00:45,763] [INFO] [launch.py:139:main] 9 NCCL_SOCKET_IFNAME=eno1
ml-512-node-042: [2024-07-08 06:00:45,763] [INFO] [launch.py:139:main] 9 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-042: [2024-07-08 06:00:45,763] [INFO] [launch.py:139:main] 9 NCCL_P2P_LEVEL=NVL
ml-512-node-042: [2024-07-08 06:00:45,763] [INFO] [launch.py:139:main] 9 NCCL_DEBUG=WARN
ml-512-node-042: [2024-07-08 06:00:45,763] [INFO] [launch.py:139:main] 9 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-042: [2024-07-08 06:00:45,763] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-042: [2024-07-08 06:00:45,763] [INFO] [launch.py:152:main] nnodes=16, num_local_procs=8, node_rank=9
ml-512-node-042: [2024-07-08 06:00:45,763] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127]})
ml-512-node-042: [2024-07-08 06:00:45,763] [INFO] [launch.py:164:main] dist_world_size=128
ml-512-node-042: [2024-07-08 06:00:45,763] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-043: [2024-07-08 06:00:45,765] [INFO] [launch.py:256:main] process 1058747 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 06:00:45,764] [INFO] [launch.py:256:main] process 1054913 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-043: [2024-07-08 06:00:45,765] [INFO] [launch.py:256:main] process 1058748 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 06:00:45,765] [INFO] [launch.py:256:main] process 1054914 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 06:00:45,766] [INFO] [launch.py:256:main] process 1054915 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 06:00:45,766] [INFO] [launch.py:256:main] process 1054916 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 06:00:45,767] [INFO] [launch.py:256:main] process 1054917 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 06:00:45,768] [INFO] [launch.py:139:main] 11 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-044: [2024-07-08 06:00:45,768] [INFO] [launch.py:139:main] 11 NCCL_SOCKET_IFNAME=eno1
ml-512-node-044: [2024-07-08 06:00:45,768] [INFO] [launch.py:139:main] 11 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-044: [2024-07-08 06:00:45,768] [INFO] [launch.py:139:main] 11 NCCL_P2P_LEVEL=NVL
ml-512-node-044: [2024-07-08 06:00:45,768] [INFO] [launch.py:139:main] 11 NCCL_DEBUG=WARN
ml-512-node-044: [2024-07-08 06:00:45,768] [INFO] [launch.py:139:main] 11 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-044: [2024-07-08 06:00:45,768] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-044: [2024-07-08 06:00:45,768] [INFO] [launch.py:152:main] nnodes=16, num_local_procs=8, node_rank=11
ml-512-node-044: [2024-07-08 06:00:45,768] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127]})
ml-512-node-044: [2024-07-08 06:00:45,768] [INFO] [launch.py:164:main] dist_world_size=128
ml-512-node-044: [2024-07-08 06:00:45,768] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-042: [2024-07-08 06:00:45,767] [INFO] [launch.py:256:main] process 1054918 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 06:00:45,769] [INFO] [launch.py:256:main] process 1053250 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 06:00:45,768] [INFO] [launch.py:256:main] process 1054919 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 06:00:45,770] [INFO] [launch.py:256:main] process 1053251 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 06:00:45,769] [INFO] [launch.py:256:main] process 1054920 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 06:00:45,771] [INFO] [launch.py:256:main] process 1053252 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 06:00:45,771] [INFO] [launch.py:256:main] process 1053253 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 06:00:45,771] [INFO] [launch.py:256:main] process 1053254 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 06:00:45,772] [INFO] [launch.py:256:main] process 1053255 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 06:00:45,773] [INFO] [launch.py:256:main] process 1053256 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 06:00:45,773] [INFO] [launch.py:256:main] process 1053257 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-046: [2024-07-08 06:00:45,779] [INFO] [launch.py:139:main] 13 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-046: [2024-07-08 06:00:45,779] [INFO] [launch.py:139:main] 13 NCCL_SOCKET_IFNAME=eno1
ml-512-node-046: [2024-07-08 06:00:45,779] [INFO] [launch.py:139:main] 13 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-046: [2024-07-08 06:00:45,779] [INFO] [launch.py:139:main] 13 NCCL_P2P_LEVEL=NVL
ml-512-node-046: [2024-07-08 06:00:45,779] [INFO] [launch.py:139:main] 13 NCCL_DEBUG=WARN
ml-512-node-046: [2024-07-08 06:00:45,779] [INFO] [launch.py:139:main] 13 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-046: [2024-07-08 06:00:45,779] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-046: [2024-07-08 06:00:45,779] [INFO] [launch.py:152:main] nnodes=16, num_local_procs=8, node_rank=13
ml-512-node-046: [2024-07-08 06:00:45,779] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127]})
ml-512-node-046: [2024-07-08 06:00:45,779] [INFO] [launch.py:164:main] dist_world_size=128
ml-512-node-046: [2024-07-08 06:00:45,779] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-046: [2024-07-08 06:00:45,780] [INFO] [launch.py:256:main] process 1054858 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-046: [2024-07-08 06:00:45,781] [INFO] [launch.py:256:main] process 1054859 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-046: [2024-07-08 06:00:45,782] [INFO] [launch.py:256:main] process 1054860 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-046: [2024-07-08 06:00:45,782] [INFO] [launch.py:256:main] process 1054861 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-046: [2024-07-08 06:00:45,782] [INFO] [launch.py:256:main] process 1054862 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-046: [2024-07-08 06:00:45,783] [INFO] [launch.py:256:main] process 1054863 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-046: [2024-07-08 06:00:45,784] [INFO] [launch.py:256:main] process 1054864 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-046: [2024-07-08 06:00:45,784] [INFO] [launch.py:256:main] process 1054865 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-041: [2024-07-08 06:00:45,877] [INFO] [launch.py:139:main] 8 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-041: [2024-07-08 06:00:45,877] [INFO] [launch.py:139:main] 8 NCCL_SOCKET_IFNAME=eno1
ml-512-node-041: [2024-07-08 06:00:45,877] [INFO] [launch.py:139:main] 8 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-041: [2024-07-08 06:00:45,877] [INFO] [launch.py:139:main] 8 NCCL_P2P_LEVEL=NVL
ml-512-node-041: [2024-07-08 06:00:45,878] [INFO] [launch.py:139:main] 8 NCCL_DEBUG=WARN
ml-512-node-041: [2024-07-08 06:00:45,878] [INFO] [launch.py:139:main] 8 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-041: [2024-07-08 06:00:45,878] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-041: [2024-07-08 06:00:45,878] [INFO] [launch.py:152:main] nnodes=16, num_local_procs=8, node_rank=8
ml-512-node-041: [2024-07-08 06:00:45,878] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127]})
ml-512-node-041: [2024-07-08 06:00:45,878] [INFO] [launch.py:164:main] dist_world_size=128
ml-512-node-041: [2024-07-08 06:00:45,878] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-041: [2024-07-08 06:00:45,879] [INFO] [launch.py:256:main] process 1061388 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-041: [2024-07-08 06:00:45,879] [INFO] [launch.py:256:main] process 1061389 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-041: [2024-07-08 06:00:45,880] [INFO] [launch.py:256:main] process 1061390 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-041: [2024-07-08 06:00:45,881] [INFO] [launch.py:256:main] process 1061391 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-041: [2024-07-08 06:00:45,881] [INFO] [launch.py:256:main] process 1061392 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-041: [2024-07-08 06:00:45,882] [INFO] [launch.py:256:main] process 1061393 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-041: [2024-07-08 06:00:45,882] [INFO] [launch.py:256:main] process 1061394 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-041: [2024-07-08 06:00:45,883] [INFO] [launch.py:256:main] process 1061395 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 06:00:46,022] [INFO] [launch.py:139:main] 7 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-040: [2024-07-08 06:00:46,022] [INFO] [launch.py:139:main] 7 NCCL_SOCKET_IFNAME=eno1
ml-512-node-040: [2024-07-08 06:00:46,022] [INFO] [launch.py:139:main] 7 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-040: [2024-07-08 06:00:46,022] [INFO] [launch.py:139:main] 7 NCCL_P2P_LEVEL=NVL
ml-512-node-040: [2024-07-08 06:00:46,022] [INFO] [launch.py:139:main] 7 NCCL_DEBUG=WARN
ml-512-node-040: [2024-07-08 06:00:46,022] [INFO] [launch.py:139:main] 7 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-040: [2024-07-08 06:00:46,022] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-040: [2024-07-08 06:00:46,022] [INFO] [launch.py:152:main] nnodes=16, num_local_procs=8, node_rank=7
ml-512-node-040: [2024-07-08 06:00:46,022] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127]})
ml-512-node-040: [2024-07-08 06:00:46,022] [INFO] [launch.py:164:main] dist_world_size=128
ml-512-node-040: [2024-07-08 06:00:46,022] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-040: [2024-07-08 06:00:46,023] [INFO] [launch.py:256:main] process 1110525 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 06:00:46,024] [INFO] [launch.py:256:main] process 1110526 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 06:00:46,025] [INFO] [launch.py:256:main] process 1110527 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 06:00:46,025] [INFO] [launch.py:256:main] process 1110528 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 06:00:46,026] [INFO] [launch.py:256:main] process 1110529 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 06:00:46,027] [INFO] [launch.py:256:main] process 1110530 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 06:00:46,027] [INFO] [launch.py:256:main] process 1110531 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 06:00:46,028] [INFO] [launch.py:256:main] process 1110532 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 06:00:48,580] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [2024-07-08 06:00:48,669] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [2024-07-08 06:00:48,717] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [2024-07-08 06:00:48,885] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [2024-07-08 06:00:49,121] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [2024-07-08 06:00:49,161] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [2024-07-08 06:00:49,223] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [2024-07-08 06:00:49,260] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [2024-07-08 06:00:49,867] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [2024-07-08 06:00:50,032] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-033: [2024-07-08 06:00:50,032] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
ml-512-node-035: [2024-07-08 06:00:50,095] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-048: [2024-07-08 06:00:50,177] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [2024-07-08 06:00:50,239] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [2024-07-08 06:00:50,269] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [2024-07-08 06:00:50,289] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: [2024-07-08 06:00:50,328] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-033: [2024-07-08 06:00:50,429] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-033: [2024-07-08 06:00:50,506] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [2024-07-08 06:00:50,594] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [2024-07-08 06:00:50,628] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: [2024-07-08 06:00:50,630] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [2024-07-08 06:00:50,661] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [2024-07-08 06:00:50,663] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [2024-07-08 06:00:50,730] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [2024-07-08 06:00:50,738] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-036: [2024-07-08 06:00:50,756] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [2024-07-08 06:00:50,789] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [2024-07-08 06:00:50,818] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [2024-07-08 06:00:50,872] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [2024-07-08 06:00:50,877] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [2024-07-08 06:00:50,904] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [2024-07-08 06:00:50,907] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [2024-07-08 06:00:50,939] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: [2024-07-08 06:00:50,946] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [2024-07-08 06:00:50,949] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [2024-07-08 06:00:50,971] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [2024-07-08 06:00:50,986] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [2024-07-08 06:00:51,007] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [2024-07-08 06:00:51,010] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [2024-07-08 06:00:51,041] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [2024-07-08 06:00:51,046] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [2024-07-08 06:00:51,055] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [2024-07-08 06:00:51,073] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [2024-07-08 06:00:51,076] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [2024-07-08 06:00:51,080] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [2024-07-08 06:00:51,080] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [2024-07-08 06:00:51,087] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [2024-07-08 06:00:51,091] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [2024-07-08 06:00:51,098] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [2024-07-08 06:00:51,112] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [2024-07-08 06:00:51,127] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [2024-07-08 06:00:51,128] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [2024-07-08 06:00:51,135] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [2024-07-08 06:00:51,135] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [2024-07-08 06:00:51,153] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [2024-07-08 06:00:51,165] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [2024-07-08 06:00:51,165] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-043: [2024-07-08 06:00:51,170] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [2024-07-08 06:00:51,198] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [2024-07-08 06:00:51,205] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-033: [2024-07-08 06:00:51,209] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-045: [2024-07-08 06:00:51,220] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [2024-07-08 06:00:51,250] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-048: [2024-07-08 06:00:51,276] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [2024-07-08 06:00:51,287] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [2024-07-08 06:00:51,292] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: [2024-07-08 06:00:51,297] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [2024-07-08 06:00:51,317] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [2024-07-08 06:00:51,323] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: [2024-07-08 06:00:51,323] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [2024-07-08 06:00:51,330] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [2024-07-08 06:00:51,354] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [2024-07-08 06:00:51,355] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [2024-07-08 06:00:51,357] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [2024-07-08 06:00:51,362] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [2024-07-08 06:00:51,368] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [2024-07-08 06:00:51,368] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [2024-07-08 06:00:51,371] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [2024-07-08 06:00:51,370] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [2024-07-08 06:00:51,373] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-041: [2024-07-08 06:00:51,380] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [2024-07-08 06:00:51,381] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [2024-07-08 06:00:51,394] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [2024-07-08 06:00:51,401] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [2024-07-08 06:00:51,402] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-035: [2024-07-08 06:00:51,405] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [2024-07-08 06:00:51,420] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [2024-07-08 06:00:51,428] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [2024-07-08 06:00:51,434] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [2024-07-08 06:00:51,438] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [2024-07-08 06:00:51,459] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [2024-07-08 06:00:51,459] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [2024-07-08 06:00:51,459] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [2024-07-08 06:00:51,462] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [2024-07-08 06:00:51,476] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [2024-07-08 06:00:51,490] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [2024-07-08 06:00:51,491] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [2024-07-08 06:00:51,498] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-041: [2024-07-08 06:00:51,501] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [2024-07-08 06:00:51,529] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [2024-07-08 06:00:51,530] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [2024-07-08 06:00:51,540] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [2024-07-08 06:00:51,546] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [2024-07-08 06:00:51,554] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [2024-07-08 06:00:51,555] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [2024-07-08 06:00:51,560] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [2024-07-08 06:00:51,563] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [2024-07-08 06:00:51,569] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [2024-07-08 06:00:51,578] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [2024-07-08 06:00:51,601] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [2024-07-08 06:00:51,616] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [2024-07-08 06:00:51,620] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [2024-07-08 06:00:51,624] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-048: [2024-07-08 06:00:51,626] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [2024-07-08 06:00:51,629] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [2024-07-08 06:00:51,628] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [2024-07-08 06:00:51,632] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [2024-07-08 06:00:51,644] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [2024-07-08 06:00:51,647] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [2024-07-08 06:00:51,655] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [2024-07-08 06:00:51,669] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [2024-07-08 06:00:51,677] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [2024-07-08 06:00:51,680] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [2024-07-08 06:00:51,681] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [2024-07-08 06:00:51,707] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [2024-07-08 06:00:51,713] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [2024-07-08 06:00:51,759] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [2024-07-08 06:00:51,794] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [2024-07-08 06:00:51,853] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-040: [2024-07-08 06:00:51,863] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [2024-07-08 06:00:51,874] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [2024-07-08 06:00:51,876] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [2024-07-08 06:00:51,963] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-040: [2024-07-08 06:00:52,059] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [2024-07-08 06:00:52,115] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [2024-07-08 06:00:52,138] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-038: [2024-07-08 06:00:52,174] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 06:00:52,174] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [2024-07-08 06:00:52,316] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-040: [2024-07-08 06:00:52,331] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [2024-07-08 06:00:52,363] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [2024-07-08 06:00:52,404] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-040: [2024-07-08 06:00:52,432] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [2024-07-08 06:00:52,472] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 06:00:52,473] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [2024-07-08 06:00:52,499] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [2024-07-08 06:00:52,503] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [2024-07-08 06:00:52,541] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-039: [2024-07-08 06:00:52,543] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [2024-07-08 06:00:52,544] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [2024-07-08 06:00:52,554] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [2024-07-08 06:00:52,558] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [2024-07-08 06:00:52,568] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [2024-07-08 06:00:52,666] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [2024-07-08 06:00:52,680] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-044: [2024-07-08 06:00:52,685] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-039: [2024-07-08 06:00:52,688] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [2024-07-08 06:00:52,698] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-048: [2024-07-08 06:00:52,724] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [2024-07-08 06:00:52,742] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [2024-07-08 06:00:52,757] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [2024-07-08 06:00:52,769] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-037: [2024-07-08 06:00:52,771] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-046: [2024-07-08 06:00:52,772] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [2024-07-08 06:00:52,777] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [2024-07-08 06:00:52,792] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-039: [2024-07-08 06:00:52,796] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [2024-07-08 06:00:52,809] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-035: [2024-07-08 06:00:52,816] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [2024-07-08 06:00:52,852] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [2024-07-08 06:00:52,862] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-039: [2024-07-08 06:00:52,863] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-037: [2024-07-08 06:00:52,888] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [2024-07-08 06:00:52,889] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [2024-07-08 06:00:52,922] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-043: [2024-07-08 06:00:52,932] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-045: [2024-07-08 06:00:52,937] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-034: [2024-07-08 06:00:52,941] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-042: [2024-07-08 06:00:52,955] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [2024-07-08 06:00:52,962] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-036: [2024-07-08 06:00:52,974] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [2024-07-08 06:00:52,989] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [2024-07-08 06:00:52,995] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [2024-07-08 06:00:53,016] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [2024-07-08 06:00:53,036] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [2024-07-08 06:00:53,041] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [2024-07-08 06:00:53,047] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-037: [2024-07-08 06:00:53,060] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [2024-07-08 06:00:53,091] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-047: [2024-07-08 06:00:53,098] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-034: [2024-07-08 06:00:53,100] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-044: [2024-07-08 06:00:53,112] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-036: [2024-07-08 06:00:53,119] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-047: [2024-07-08 06:00:53,130] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-043: [2024-07-08 06:00:53,138] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [2024-07-08 06:00:53,139] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-045: [2024-07-08 06:00:53,156] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [2024-07-08 06:00:53,156] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-036: [2024-07-08 06:00:53,161] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-045: [2024-07-08 06:00:53,166] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [2024-07-08 06:00:53,183] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-042: [2024-07-08 06:00:53,184] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-034: [2024-07-08 06:00:53,194] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-043: [2024-07-08 06:00:53,195] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [2024-07-08 06:00:53,228] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [2024-07-08 06:00:53,263] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [2024-07-08 06:00:53,269] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-042: [2024-07-08 06:00:53,274] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-037: [2024-07-08 06:00:53,278] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [2024-07-08 06:00:53,278] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-036: [2024-07-08 06:00:53,283] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-034: [2024-07-08 06:00:53,294] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-036: [2024-07-08 06:00:53,301] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-036: [2024-07-08 06:00:53,308] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-042: [2024-07-08 06:00:53,311] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-037: [2024-07-08 06:00:53,326] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-037: [2024-07-08 06:00:53,349] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-047: [2024-07-08 06:00:53,352] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [2024-07-08 06:00:53,360] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-034: [2024-07-08 06:00:53,365] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-039: [2024-07-08 06:00:53,386] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-043: [2024-07-08 06:00:53,386] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-047: [2024-07-08 06:00:53,406] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-046: [2024-07-08 06:00:53,410] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-035: [2024-07-08 06:00:53,412] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-046: [2024-07-08 06:00:53,434] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-047: [2024-07-08 06:00:53,440] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-042: [2024-07-08 06:00:53,455] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-035: [2024-07-08 06:00:53,460] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-035: [2024-07-08 06:00:53,467] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-046: [2024-07-08 06:00:53,488] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [2024-07-08 06:00:53,496] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-043: [2024-07-08 06:00:53,501] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [2024-07-08 06:00:53,510] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-039: [2024-07-08 06:00:53,510] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [2024-07-08 06:00:53,514] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-034: [2024-07-08 06:00:53,518] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-042: [2024-07-08 06:00:53,520] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-034: [2024-07-08 06:00:53,524] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-044: [2024-07-08 06:00:53,528] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [2024-07-08 06:00:53,594] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-045: [2024-07-08 06:00:53,614] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-044: [2024-07-08 06:00:53,667] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-044: [2024-07-08 06:00:53,669] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-044: [2024-07-08 06:00:53,669] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [2024-07-08 06:00:53,676] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-046: [2024-07-08 06:00:53,717] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [2024-07-08 06:00:53,737] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 06:00:53,758] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [2024-07-08 06:00:53,969] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 06:00:54,070] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 06:00:54,101] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 06:00:54,104] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 06:00:54,277] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 06:00:54,400] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 06:00:54,620] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-033: NCCL version 2.19.4+cuda12.2
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-038:   warnings.warn(
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033:   warnings.warn(
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033:   warnings.warn(
ml-512-node-045:   warnings.warn(
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-045:   warnings.warn(
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-045:   warnings.warn(
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-038:   warnings.warn(
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-045:   warnings.warn(
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-035:   warnings.warn(
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-035:   warnings.warn(
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-035:   warnings.warn(
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-045:   warnings.warn(
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-035:   warnings.warn(
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-035:   warnings.warn(
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-035:   warnings.warn(
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-045:   warnings.warn(
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-035:   warnings.warn(
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-035:   warnings.warn(
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036:   warnings.warn(
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036:   warnings.warn(
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036:   warnings.warn(
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-034:   warnings.warn(
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-034:   warnings.warn(
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-046:   warnings.warn(
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039:   warnings.warn(
ml-512-node-046:   warnings.warn(
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039:   warnings.warn(
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039:   warnings.warn(
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-048:   warnings.warn(
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037:   warnings.warn(
ml-512-node-039:   warnings.warn(
ml-512-node-046:   warnings.warn(
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-048:   warnings.warn(
ml-512-node-033:   warnings.warn(
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-048:   warnings.warn(
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033:   warnings.warn(
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-046:   warnings.warn(
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033:   warnings.warn(
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-046:   warnings.warn(
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033:   warnings.warn(
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042:   warnings.warn(
ml-512-node-033:   warnings.warn(
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033:   warnings.warn(
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039:   warnings.warn(
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039:   warnings.warn(
ml-512-node-045:   warnings.warn(
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-045:   warnings.warn(
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-040:   warnings.warn(
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-040:   warnings.warn(
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-040:   warnings.warn(
ml-512-node-048:   warnings.warn(
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-048:   warnings.warn(
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-048:   warnings.warn(
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-040:   warnings.warn(
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-040:   warnings.warn(
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-048:   warnings.warn(
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-048:   warnings.warn(
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039:   warnings.warn(
ml-512-node-037:   warnings.warn(
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037:   warnings.warn(
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037:   warnings.warn(
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-038:   warnings.warn(
ml-512-node-037:   warnings.warn(
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-038:   warnings.warn(
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036:   warnings.warn(
ml-512-node-047:   warnings.warn(
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036:   warnings.warn(
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047:   warnings.warn(
ml-512-node-036:   warnings.warn(
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-038:   warnings.warn(
ml-512-node-037:   warnings.warn(
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036:   warnings.warn(
ml-512-node-046:   warnings.warn(
ml-512-node-034:   warnings.warn(
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-043:   warnings.warn(
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044:   warnings.warn(
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044:   warnings.warn(
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039:   warnings.warn(
ml-512-node-034:   warnings.warn(
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-034:   warnings.warn(
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042:   warnings.warn(
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042:   warnings.warn(
ml-512-node-040:   warnings.warn(
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044:   warnings.warn(
ml-512-node-040:   warnings.warn(
ml-512-node-038:   warnings.warn(
ml-512-node-046:   warnings.warn(
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047:   warnings.warn(
ml-512-node-038:   warnings.warn(
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044:   warnings.warn(
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047:   warnings.warn(
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047:   warnings.warn(
ml-512-node-038:   warnings.warn(
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044:   warnings.warn(
ml-512-node-046:   warnings.warn(
ml-512-node-043:   warnings.warn(
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-041:   warnings.warn(
ml-512-node-047:   warnings.warn(
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044:   warnings.warn(
ml-512-node-034:   warnings.warn(
ml-512-node-043:   warnings.warn(
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044:   warnings.warn(
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-034:   warnings.warn(
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-041:   warnings.warn(
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-041:   warnings.warn(
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-041:   warnings.warn(
ml-512-node-047:   warnings.warn(
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-034:   warnings.warn(
ml-512-node-043:   warnings.warn(
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047:   warnings.warn(
ml-512-node-041:   warnings.warn(
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-041:   warnings.warn(
ml-512-node-043:   warnings.warn(
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-043:   warnings.warn(
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036:   warnings.warn(
ml-512-node-043:   warnings.warn(
ml-512-node-042:   warnings.warn(
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042:   warnings.warn(
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042:   warnings.warn(
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042:   warnings.warn(
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042:   warnings.warn(
ml-512-node-041:   warnings.warn(
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-040:   warnings.warn(
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044:   warnings.warn(
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-041:   warnings.warn(
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037:   warnings.warn(
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037:   warnings.warn(
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-043:   warnings.warn(
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Detected CUDA files, patching ldflags
ml-512-node-040: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-040: Building extension module fused_adam...
ml-512-node-040: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: ninja: no work to do.
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-040: Time to load fused_adam op: 0.10130119323730469 seconds
ml-512-node-040: Time to load fused_adam op: 0.10132169723510742 seconds
ml-512-node-040: Detected CUDA files, patching ldflags
ml-512-node-040: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-040: Building extension module fused_adam...
ml-512-node-040: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Detected CUDA files, patching ldflags
ml-512-node-037: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-037: Building extension module fused_adam...
ml-512-node-037: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-041: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: ninja: no work to do.
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-037: Time to load fused_adam op: 0.06355142593383789 seconds
ml-512-node-041: Detected CUDA files, patching ldflags
ml-512-node-041: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-041: Building extension module fused_adam...
ml-512-node-041: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-041: ninja: no work to do.
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-041: Time to load fused_adam op: 0.06439065933227539 seconds
ml-512-node-040: ninja: no work to do.
ml-512-node-040: Time to load fused_adam op: 0.3984410762786865 seconds
ml-512-node-040: Time to load fused_adam op: 0.20257234573364258 seconds
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-040: Time to load fused_adam op: 0.508230447769165 seconds
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-040: Time to load fused_adam op: 0.5022039413452148 seconds
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: Detected CUDA files, patching ldflags
ml-512-node-043: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-043: Building extension module fused_adam...
ml-512-node-043: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-040: Time to load fused_adam op: 0.5018317699432373 seconds
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: Detected CUDA files, patching ldflags
ml-512-node-046: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-046: Building extension module fused_adam...
ml-512-node-046: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-044: Detected CUDA files, patching ldflags
ml-512-node-044: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-044: Building extension module fused_adam...
ml-512-node-044: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-043: ninja: no work to do.
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-043: Time to load fused_adam op: 0.06407499313354492 seconds
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: ninja: no work to do.
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: Time to load fused_adam op: 0.06339383125305176 seconds
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-044: ninja: no work to do.
ml-512-node-047: Detected CUDA files, patching ldflags
ml-512-node-047: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-047: Building extension module fused_adam...
ml-512-node-047: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-044: Time to load fused_adam op: 0.06286931037902832 seconds
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-039: Detected CUDA files, patching ldflags
ml-512-node-039: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-039: Building extension module fused_adam...
ml-512-node-039: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-043: Time to load fused_adam op: 0.10166096687316895 seconds
ml-512-node-035: Detected CUDA files, patching ldflags
ml-512-node-035: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-035: Building extension module fused_adam...
ml-512-node-035: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: Time to load fused_adam op: 0.10177755355834961 seconds
ml-512-node-042: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: Time to load fused_adam op: 0.10144710540771484 seconds
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-047: ninja: no work to do.
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-047: Time to load fused_adam op: 0.06419968605041504 seconds
ml-512-node-043: Time to load fused_adam op: 0.10662341117858887 seconds
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-039: ninja: no work to do.
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-039: Time to load fused_adam op: 0.06296443939208984 seconds
ml-512-node-044: Detected CUDA files, patching ldflags
ml-512-node-044: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-044: Building extension module fused_adam...
ml-512-node-044: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: Time to load fused_adam op: 0.10245895385742188 seconds
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-035: ninja: no work to do.
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-035: Time to load fused_adam op: 0.06218266487121582 seconds
ml-512-node-042: Detected CUDA files, patching ldflags
ml-512-node-042: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-042: Building extension module fused_adam...
ml-512-node-042: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-036: Detected CUDA files, patching ldflags
ml-512-node-036: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-036: Building extension module fused_adam...
ml-512-node-036: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-046: Time to load fused_adam op: 0.10468769073486328 seconds
ml-512-node-034: Detected CUDA files, patching ldflags
ml-512-node-034: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-034: Building extension module fused_adam...
ml-512-node-034: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-047: Time to load fused_adam op: 0.1013786792755127 seconds
ml-512-node-047: Time to load fused_adam op: 0.10222434997558594 seconds
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-042: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-042: ninja: no work to do.
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-047: Time to load fused_adam op: 0.11334347724914551 seconds
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-036: ninja: no work to do.
ml-512-node-042: Time to load fused_adam op: 0.06352090835571289 seconds
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-036: Time to load fused_adam op: 0.0633697509765625 seconds
ml-512-node-034: ninja: no work to do.
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-034: Time to load fused_adam op: 0.06182503700256348 seconds
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-044: ninja: no work to do.
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-048: Detected CUDA files, patching ldflags
ml-512-node-048: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-048: Building extension module fused_adam...
ml-512-node-048: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-044: Time to load fused_adam op: 0.10487842559814453 seconds
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-044: Time to load fused_adam op: 0.10217761993408203 seconds
ml-512-node-042: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Detected CUDA files, patching ldflags
ml-512-node-034: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-034: Building extension module fused_adam...
ml-512-node-034: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-048: ninja: no work to do.
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-036: Detected CUDA files, patching ldflags
ml-512-node-036: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-044: Time to load fused_adam op: 0.20159530639648438 seconds
ml-512-node-036: Building extension module fused_adam...
ml-512-node-036: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-048: Time to load fused_adam op: 0.06320357322692871 seconds
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-042: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-042: Detected CUDA files, patching ldflags
ml-512-node-042: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-042: Building extension module fused_adam...
ml-512-node-042: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-044: Time to load fused_adam op: 0.2014780044555664 seconds
ml-512-node-044: Time to load fused_adam op: 0.20183730125427246 seconds
ml-512-node-044: Time to load fused_adam op: 0.10702109336853027 seconds
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-043: Detected CUDA files, patching ldflags
ml-512-node-043: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-043: Building extension module fused_adam...
ml-512-node-043: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-033: Detected CUDA files, patching ldflags
ml-512-node-033: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-033: Building extension module fused_adam...
ml-512-node-033: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-035: Detected CUDA files, patching ldflags
ml-512-node-035: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-035: Building extension module fused_adam...
ml-512-node-035: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-042: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: ninja: no work to do.
ml-512-node-037: Detected CUDA files, patching ldflags
ml-512-node-037: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-037: Building extension module fused_adam...
ml-512-node-037: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-036: ninja: no work to do.
ml-512-node-033: ninja: no work to do.
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-034: Time to load fused_adam op: 0.09692215919494629 seconds
ml-512-node-034: Time to load fused_adam op: 0.10243797302246094 seconds
ml-512-node-034: Time to load fused_adam op: 0.1022641658782959 seconds
ml-512-node-033: Time to load fused_adam op: 0.0612640380859375 seconds
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-038: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-048: Detected CUDA files, patching ldflags
ml-512-node-048: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-048: Building extension module fused_adam...
ml-512-node-048: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-038: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-036: Time to load fused_adam op: 0.09360504150390625 seconds
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-042: ninja: no work to do.
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-045: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-042: Time to load fused_adam op: 0.0959317684173584 seconds
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-038: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-038: Detected CUDA files, patching ldflags
ml-512-node-038: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-038: Building extension module fused_adam...
ml-512-node-038: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-038: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: ninja: no work to do.
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-037: Time to load fused_adam op: 0.14466524124145508 seconds
ml-512-node-045: Detected CUDA files, patching ldflags
ml-512-node-045: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-045: Building extension module fused_adam...
ml-512-node-045: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Time to load fused_adam op: 0.10245323181152344 seconds
ml-512-node-035: ninja: no work to do.
ml-512-node-033: Detected CUDA files, patching ldflags
ml-512-node-033: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-033: Building extension module fused_adam...
ml-512-node-033: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-038: ninja: no work to do.
ml-512-node-035: Time to load fused_adam op: 0.18456673622131348 seconds
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-039: Detected CUDA files, patching ldflags
ml-512-node-039: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-039: Building extension module fused_adam...
ml-512-node-039: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-038: Time to load fused_adam op: 0.06274795532226562 seconds
ml-512-node-042: Time to load fused_adam op: 0.10156869888305664 seconds
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-047: Detected CUDA files, patching ldflags
ml-512-node-047: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-047: Building extension module fused_adam...
ml-512-node-047: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-045: ninja: no work to do.
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-042: Time to load fused_adam op: 0.202439546585083 seconds
ml-512-node-045: Loading extension module fused_adam...
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Time to load fused_adam op: 0.1015005111694336 seconds
ml-512-node-034: Time to load fused_adam op: 0.20244646072387695 seconds
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-045: Time to load fused_adam op: 0.06342101097106934 seconds
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-048: ninja: no work to do.
ml-512-node-045: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Time to load fused_adam op: 0.20161056518554688 seconds
ml-512-node-042: Time to load fused_adam op: 0.10178613662719727 seconds
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-048: Time to load fused_adam op: 0.20160984992980957 seconds
ml-512-node-048: Time to load fused_adam op: 0.15247321128845215 seconds
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-035: Time to load fused_adam op: 0.30162787437438965 seconds
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-038: Time to load fused_adam op: 0.1016535758972168 seconds
ml-512-node-035: Time to load fused_adam op: 0.30309391021728516 seconds
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-035: Time to load fused_adam op: 0.302476167678833 seconds
ml-512-node-045: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-042: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-037: Time to load fused_adam op: 0.20266509056091309 seconds
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-037: Time to load fused_adam op: 0.2025907039642334 seconds
ml-512-node-042: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-033: ninja: no work to do.
ml-512-node-035: Time to load fused_adam op: 0.3018763065338135 seconds
ml-512-node-035: Time to load fused_adam op: 0.30255842208862305 seconds
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-045: Detected CUDA files, patching ldflags
ml-512-node-045: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-045: Building extension module fused_adam...
ml-512-node-045: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-033: Time to load fused_adam op: 0.1132669448852539 seconds
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-038: Time to load fused_adam op: 0.10136938095092773 seconds
ml-512-node-037: Time to load fused_adam op: 0.20795035362243652 seconds
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-039: ninja: no work to do.
ml-512-node-041: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: Detected CUDA files, patching ldflags
ml-512-node-046: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-039: Time to load fused_adam op: 0.1557016372680664 seconds
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-033: Time to load fused_adam op: 0.10431456565856934 seconds
ml-512-node-038: Time to load fused_adam op: 0.1058046817779541 seconds
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-038: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-048: Time to load fused_adam op: 0.20166897773742676 seconds
ml-512-node-048: Time to load fused_adam op: 0.2023334503173828 seconds
ml-512-node-048: Time to load fused_adam op: 0.2018904685974121 seconds
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-047: ninja: no work to do.
ml-512-node-033: Time to load fused_adam op: 0.20148515701293945 seconds
ml-512-node-033: Time to load fused_adam op: 0.20148205757141113 seconds
ml-512-node-033: Time to load fused_adam op: 0.10548162460327148 seconds
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-047: Time to load fused_adam op: 0.2645096778869629 seconds
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-043: ninja: no work to do.
ml-512-node-043: Time to load fused_adam op: 0.3193681240081787 seconds
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-046: Building extension module fused_adam...
ml-512-node-046: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-036: Detected CUDA files, patching ldflags
ml-512-node-036: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-036: Building extension module fused_adam...
ml-512-node-036: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-048: Time to load fused_adam op: 0.20253705978393555 seconds
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-039: Time to load fused_adam op: 0.10167455673217773 seconds
ml-512-node-045: ninja: no work to do.
ml-512-node-043: Time to load fused_adam op: 0.10276412963867188 seconds
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-045: Time to load fused_adam op: 0.10248184204101562 seconds
ml-512-node-045: Loading extension module fused_adam...
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-042: Detected CUDA files, patching ldflags
ml-512-node-042: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-042: Building extension module fused_adam...
ml-512-node-042: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-045: Loading extension module fused_adam...
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-039: Time to load fused_adam op: 0.10723304748535156 seconds
ml-512-node-039: Time to load fused_adam op: 0.10239171981811523 seconds
ml-512-node-039: Time to load fused_adam op: 0.10239887237548828 seconds
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-045: Time to load fused_adam op: 0.1017007827758789 seconds
ml-512-node-047: Time to load fused_adam op: 0.3017544746398926 seconds
ml-512-node-041: Detected CUDA files, patching ldflags
ml-512-node-041: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-041: Building extension module fused_adam...
ml-512-node-041: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-036: ninja: no work to do.
ml-512-node-039: Time to load fused_adam op: 0.20202326774597168 seconds
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-036: Time to load fused_adam op: 0.1545579433441162 seconds
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-047: Time to load fused_adam op: 0.30274105072021484 seconds
ml-512-node-047: Time to load fused_adam op: 0.3116481304168701 seconds
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-038: Detected CUDA files, patching ldflags
ml-512-node-038: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-038: Building extension module fused_adam...
ml-512-node-038: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-036: Time to load fused_adam op: 0.1015315055847168 seconds
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-043: Time to load fused_adam op: 0.3087308406829834 seconds
ml-512-node-045: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: ninja: no work to do.
ml-512-node-045: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-038: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-036: Time to load fused_adam op: 0.10247540473937988 seconds
ml-512-node-046: Time to load fused_adam op: 0.2813718318939209 seconds
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-033: Detected CUDA files, patching ldflags
ml-512-node-033: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-033: Building extension module fused_adam...
ml-512-node-033: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-042: ninja: no work to do.
ml-512-node-041: ninja: no work to do.
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-041: Time to load fused_adam op: 0.1903524398803711 seconds
ml-512-node-042: Time to load fused_adam op: 0.21191024780273438 seconds
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-042: Time to load fused_adam op: 0.2091073989868164 seconds
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-046: Time to load fused_adam op: 0.3132452964782715 seconds
ml-512-node-046: Time to load fused_adam op: 0.20291781425476074 seconds
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-038: ninja: no work to do.
ml-512-node-041: Time to load fused_adam op: 0.20282220840454102 seconds
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-038: Time to load fused_adam op: 0.18195724487304688 seconds
ml-512-node-046: Time to load fused_adam op: 0.3028249740600586 seconds
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-045: Detected CUDA files, patching ldflags
ml-512-node-045: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-045: Building extension module fused_adam...
ml-512-node-045: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-041: Time to load fused_adam op: 0.20523452758789062 seconds
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-041: Time to load fused_adam op: 0.101593017578125 seconds
ml-512-node-038: Time to load fused_adam op: 0.10260748863220215 seconds
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-041: Time to load fused_adam op: 0.10167169570922852 seconds
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-036: Detected CUDA files, patching ldflags
ml-512-node-036: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-036: Building extension module fused_adam...
ml-512-node-036: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-045: ninja: no work to do.
ml-512-node-045: Time to load fused_adam op: 0.1910848617553711 seconds
ml-512-node-045: Loading extension module fused_adam...
ml-512-node-045: Time to load fused_adam op: 0.20812487602233887 seconds
ml-512-node-045: Loading extension module fused_adam...
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-036: ninja: no work to do.
ml-512-node-036: Time to load fused_adam op: 0.2223360538482666 seconds
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-033: ninja: no work to do.
ml-512-node-033: Time to load fused_adam op: 0.38365840911865234 seconds
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-048: Detected CUDA files, patching ldflags
ml-512-node-048: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-048: Building extension module fused_adam...
ml-512-node-048: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-033: Time to load fused_adam op: 0.6019866466522217 seconds
ml-512-node-033: [2024-07-08 06:01:26,313] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.4, git-hash=unknown, git-branch=unknown
ml-512-node-033: [2024-07-08 06:01:26,313] [INFO] [comm.py:662:init_distributed] Distributed backend already initialized
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-044: Detected CUDA files, patching ldflags
ml-512-node-044: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-044: Building extension module fused_adam...
ml-512-node-044: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-048: ninja: no work to do.
ml-512-node-048: Time to load fused_adam op: 0.37448549270629883 seconds
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-046: Detected CUDA files, patching ldflags
ml-512-node-046: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-046: Building extension module fused_adam...
ml-512-node-046: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-040: Detected CUDA files, patching ldflags
ml-512-node-040: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-040: Building extension module fused_adam...
ml-512-node-040: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-044: ninja: no work to do.
ml-512-node-044: Time to load fused_adam op: 0.4472041130065918 seconds
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-046: ninja: no work to do.
ml-512-node-046: Time to load fused_adam op: 0.3192875385284424 seconds
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-038: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-038: Detected CUDA files, patching ldflags
ml-512-node-038: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-038: Building extension module fused_adam...
ml-512-node-038: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-038: ninja: no work to do.
ml-512-node-040: ninja: no work to do.
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-040: Time to load fused_adam op: 0.9639651775360107 seconds
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-038: Time to load fused_adam op: 0.2610971927642822 seconds
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-045: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-038: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-036: Detected CUDA files, patching ldflags
ml-512-node-036: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-036: Building extension module fused_adam...
ml-512-node-036: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-045: Detected CUDA files, patching ldflags
ml-512-node-045: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-045: Building extension module fused_adam...
ml-512-node-045: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-042: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Detected CUDA files, patching ldflags
ml-512-node-037: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-037: Building extension module fused_adam...
ml-512-node-037: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-038: Detected CUDA files, patching ldflags
ml-512-node-038: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-038: Building extension module fused_adam...
ml-512-node-038: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-036: ninja: no work to do.
ml-512-node-038: ninja: no work to do.
ml-512-node-036: Time to load fused_adam op: 0.43859219551086426 seconds
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-042: Detected CUDA files, patching ldflags
ml-512-node-042: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-042: Building extension module fused_adam...
ml-512-node-042: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-038: Time to load fused_adam op: 0.375316858291626 seconds
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-045: ninja: no work to do.
ml-512-node-045: Loading extension module fused_adam...
ml-512-node-045: Time to load fused_adam op: 0.45173192024230957 seconds
ml-512-node-037: ninja: no work to do.
ml-512-node-037: Time to load fused_adam op: 0.4035525321960449 seconds
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-042: ninja: no work to do.
ml-512-node-042: Time to load fused_adam op: 0.36537766456604004 seconds
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Detected CUDA files, patching ldflags
ml-512-node-037: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-037: Building extension module fused_adam...
ml-512-node-037: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-041: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-036: Detected CUDA files, patching ldflags
ml-512-node-036: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-036: Building extension module fused_adam...
ml-512-node-036: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: ninja: no work to do.
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-037: Time to load fused_adam op: 0.35335397720336914 seconds
ml-512-node-041: Detected CUDA files, patching ldflags
ml-512-node-041: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-041: Building extension module fused_adam...
ml-512-node-041: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-035: Detected CUDA files, patching ldflags
ml-512-node-035: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-035: Building extension module fused_adam...
ml-512-node-035: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-037: Time to load fused_adam op: 0.11203122138977051 seconds
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-036: ninja: no work to do.
ml-512-node-036: Time to load fused_adam op: 0.3351411819458008 seconds
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-041: ninja: no work to do.
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-035: ninja: no work to do.
ml-512-node-035: Time to load fused_adam op: 0.2766761779785156 seconds
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-041: Time to load fused_adam op: 0.28933262825012207 seconds
ml-512-node-045: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Time to load fused_adam op: 0.3058032989501953 seconds
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-045: Detected CUDA files, patching ldflags
ml-512-node-045: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-045: Building extension module fused_adam...
ml-512-node-045: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-045: ninja: no work to do.
ml-512-node-045: Loading extension module fused_adam...
ml-512-node-045: Time to load fused_adam op: 0.28899073600769043 seconds
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-039: Detected CUDA files, patching ldflags
ml-512-node-039: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-039: Building extension module fused_adam...
ml-512-node-039: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-039: ninja: no work to do.
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-039: Time to load fused_adam op: 0.3333160877227783 seconds
ml-512-node-045: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-045: Detected CUDA files, patching ldflags
ml-512-node-045: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-045: Building extension module fused_adam...
ml-512-node-045: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-045: ninja: no work to do.
ml-512-node-045: Time to load fused_adam op: 0.2684950828552246 seconds
ml-512-node-045: Loading extension module fused_adam...
ml-512-node-033: [2024-07-08 06:01:46,007] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
ml-512-node-033: [2024-07-08 06:01:46,009] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
ml-512-node-033: [2024-07-08 06:01:46,009] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
ml-512-node-033: [2024-07-08 06:01:46,018] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
ml-512-node-033: [2024-07-08 06:01:46,018] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 optimizer with dynamic loss scale
ml-512-node-033: [2024-07-08 06:01:46,117] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FP16_Optimizer
ml-512-node-033: [2024-07-08 06:01:46,118] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
ml-512-node-033: [2024-07-08 06:01:46,118] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x7a8d4c1438e0>
ml-512-node-033: [2024-07-08 06:01:46,118] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 06:01:46,118] [INFO] [config.py:997:print] DeepSpeedEngine configuration:
ml-512-node-033: [2024-07-08 06:01:46,118] [INFO] [config.py:1001:print]   activation_checkpointing_config  {
ml-512-node-033:     "partition_activations": false, 
ml-512-node-033:     "contiguous_memory_optimization": false, 
ml-512-node-033:     "cpu_checkpointing": false, 
ml-512-node-033:     "number_checkpoints": null, 
ml-512-node-033:     "synchronize_checkpoint_boundary": false, 
ml-512-node-033:     "profile": false
ml-512-node-033: }
ml-512-node-033: [2024-07-08 06:01:46,119] [INFO] [config.py:1001:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
ml-512-node-033: [2024-07-08 06:01:46,119] [INFO] [config.py:1001:print]   amp_enabled .................. False
ml-512-node-033: [2024-07-08 06:01:46,119] [INFO] [config.py:1001:print]   amp_params ................... False
ml-512-node-033: [2024-07-08 06:01:46,119] [INFO] [config.py:1001:print]   autotuning_config ............ {
ml-512-node-033:     "enabled": false, 
ml-512-node-033:     "start_step": null, 
ml-512-node-033:     "end_step": null, 
ml-512-node-033:     "metric_path": null, 
ml-512-node-033:     "arg_mappings": null, 
ml-512-node-033:     "metric": "throughput", 
ml-512-node-033:     "model_info": null, 
ml-512-node-033:     "results_dir": "autotuning_results", 
ml-512-node-033:     "exps_dir": "autotuning_exps", 
ml-512-node-033:     "overwrite": true, 
ml-512-node-033:     "fast": true, 
ml-512-node-033:     "start_profile_step": 3, 
ml-512-node-033:     "end_profile_step": 5, 
ml-512-node-033:     "tuner_type": "gridsearch", 
ml-512-node-033:     "tuner_early_stopping": 5, 
ml-512-node-033:     "tuner_num_trials": 50, 
ml-512-node-033:     "model_info_path": null, 
ml-512-node-033:     "mp_size": 1, 
ml-512-node-033:     "max_train_batch_size": null, 
ml-512-node-033:     "min_train_batch_size": 1, 
ml-512-node-033:     "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
ml-512-node-033:     "min_train_micro_batch_size_per_gpu": 1, 
ml-512-node-033:     "num_tuning_micro_batch_sizes": 3
ml-512-node-033: }
ml-512-node-033: [2024-07-08 06:01:46,119] [INFO] [config.py:1001:print]   bfloat16_enabled ............. False
ml-512-node-033: [2024-07-08 06:01:46,119] [INFO] [config.py:1001:print]   bfloat16_immediate_grad_update  False
ml-512-node-033: [2024-07-08 06:01:46,119] [INFO] [config.py:1001:print]   checkpoint_parallel_write_pipeline  False
ml-512-node-033: [2024-07-08 06:01:46,119] [INFO] [config.py:1001:print]   checkpoint_tag_validation_enabled  True
ml-512-node-033: [2024-07-08 06:01:46,119] [INFO] [config.py:1001:print]   checkpoint_tag_validation_fail  False
ml-512-node-033: [2024-07-08 06:01:46,119] [INFO] [config.py:1001:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7a8d4c140370>
ml-512-node-033: [2024-07-08 06:01:46,119] [INFO] [config.py:1001:print]   communication_data_type ...... None
ml-512-node-033: [2024-07-08 06:01:46,119] [INFO] [config.py:1001:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
ml-512-node-033: [2024-07-08 06:01:46,119] [INFO] [config.py:1001:print]   curriculum_enabled_legacy .... False
ml-512-node-033: [2024-07-08 06:01:46,119] [INFO] [config.py:1001:print]   curriculum_params_legacy ..... False
ml-512-node-033: [2024-07-08 06:01:46,119] [INFO] [config.py:1001:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
ml-512-node-033: [2024-07-08 06:01:46,119] [INFO] [config.py:1001:print]   data_efficiency_enabled ...... False
ml-512-node-033: [2024-07-08 06:01:46,119] [INFO] [config.py:1001:print]   dataloader_drop_last ......... False
ml-512-node-033: [2024-07-08 06:01:46,119] [INFO] [config.py:1001:print]   disable_allgather ............ False
ml-512-node-033: [2024-07-08 06:01:46,119] [INFO] [config.py:1001:print]   dump_state ................... False
ml-512-node-033: [2024-07-08 06:01:46,119] [INFO] [config.py:1001:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 100, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}
ml-512-node-033: [2024-07-08 06:01:46,119] [INFO] [config.py:1001:print]   eigenvalue_enabled ........... False
ml-512-node-033: [2024-07-08 06:01:46,119] [INFO] [config.py:1001:print]   eigenvalue_gas_boundary_resolution  1
ml-512-node-033: [2024-07-08 06:01:46,119] [INFO] [config.py:1001:print]   eigenvalue_layer_name ........ bert.encoder.layer
ml-512-node-033: [2024-07-08 06:01:46,119] [INFO] [config.py:1001:print]   eigenvalue_layer_num ......... 0
ml-512-node-033: [2024-07-08 06:01:46,119] [INFO] [config.py:1001:print]   eigenvalue_max_iter .......... 100
ml-512-node-033: [2024-07-08 06:01:46,119] [INFO] [config.py:1001:print]   eigenvalue_stability ......... 1e-06
ml-512-node-033: [2024-07-08 06:01:46,119] [INFO] [config.py:1001:print]   eigenvalue_tol ............... 0.01
ml-512-node-033: [2024-07-08 06:01:46,119] [INFO] [config.py:1001:print]   eigenvalue_verbose ........... False
ml-512-node-033: [2024-07-08 06:01:46,119] [INFO] [config.py:1001:print]   elasticity_enabled ........... False
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   flops_profiler_config ........ {
ml-512-node-033:     "enabled": false, 
ml-512-node-033:     "recompute_fwd_factor": 0.0, 
ml-512-node-033:     "profile_step": 1, 
ml-512-node-033:     "module_depth": -1, 
ml-512-node-033:     "top_modules": 1, 
ml-512-node-033:     "detailed": true, 
ml-512-node-033:     "output_file": null
ml-512-node-033: }
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   fp16_auto_cast ............... False
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   fp16_enabled ................. True
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   fp16_master_weights_and_gradients  False
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   global_rank .................. 0
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   grad_accum_dtype ............. None
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   gradient_accumulation_steps .. 1
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   gradient_clipping ............ 1.0
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   gradient_predivide_factor .... 1.0
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   graph_harvesting ............. False
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   initial_dynamic_scale ........ 65536
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   load_universal_checkpoint .... False
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   loss_scale ................... 0
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   memory_breakdown ............. False
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   mics_hierarchial_params_gather  False
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   mics_shard_size .............. -1
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='step1_tensorboard/ds_tensorboard_logs/', job_name='step1_model_tensorboard') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   nebula_config ................ {
ml-512-node-033:     "enabled": false, 
ml-512-node-033:     "persistent_storage_path": null, 
ml-512-node-033:     "persistent_time_interval": 100, 
ml-512-node-033:     "num_of_version_in_retention": 2, 
ml-512-node-033:     "enable_nebula_load": true, 
ml-512-node-033:     "load_path": null
ml-512-node-033: }
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   optimizer_legacy_fusion ...... False
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   optimizer_name ............... None
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   optimizer_params ............. None
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   pld_enabled .................. False
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   pld_params ................... False
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   prescale_gradients ........... False
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   scheduler_name ............... None
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   scheduler_params ............. None
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   seq_parallel_communication_data_type  torch.float32
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   sparse_attention ............. None
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   sparse_gradients_enabled ..... False
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   steps_per_print .............. 10
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   timers_config ................ enabled=True synchronized=True
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   train_batch_size ............. 3072
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   train_micro_batch_size_per_gpu  24
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   use_data_before_expert_parallel_  False
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   use_node_local_storage ....... False
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   wall_clock_breakdown ......... False
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   weight_quantization_config ... None
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   world_size ................... 128
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   zero_allow_untested_optimizer  False
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=30000000 param_persistence_threshold=10000 model_persistence_threshold=sys.maxsize max_live_parameters=30000000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=False pipeline_loading_checkpoint=False override_module_apply=True
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   zero_enabled ................. False
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   zero_force_ds_cpu_optimizer .. True
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:1001:print]   zero_optimization_stage ...... 0
ml-512-node-033: [2024-07-08 06:01:46,120] [INFO] [config.py:987:print_user_config]   json = {
ml-512-node-033:     "train_batch_size": 3.072000e+03, 
ml-512-node-033:     "train_micro_batch_size_per_gpu": 24, 
ml-512-node-033:     "steps_per_print": 10, 
ml-512-node-033:     "zero_optimization": {
ml-512-node-033:         "stage": 0, 
ml-512-node-033:         "offload_param": {
ml-512-node-033:             "device": "none"
ml-512-node-033:         }, 
ml-512-node-033:         "offload_optimizer": {
ml-512-node-033:             "device": "none"
ml-512-node-033:         }, 
ml-512-node-033:         "stage3_param_persistence_threshold": 1.000000e+04, 
ml-512-node-033:         "stage3_max_live_parameters": 3.000000e+07, 
ml-512-node-033:         "stage3_prefetch_bucket_size": 3.000000e+07, 
ml-512-node-033:         "memory_efficient_linear": false
ml-512-node-033:     }, 
ml-512-node-033:     "fp16": {
ml-512-node-033:         "enabled": true, 
ml-512-node-033:         "loss_scale_window": 100
ml-512-node-033:     }, 
ml-512-node-033:     "gradient_clipping": 1.0, 
ml-512-node-033:     "prescale_gradients": false, 
ml-512-node-033:     "wall_clock_breakdown": false, 
ml-512-node-033:     "hybrid_engine": {
ml-512-node-033:         "enabled": false, 
ml-512-node-033:         "max_out_tokens": 512, 
ml-512-node-033:         "inference_tp_size": 1, 
ml-512-node-033:         "release_inference_cache": false, 
ml-512-node-033:         "pin_parameters": true, 
ml-512-node-033:         "tp_gather_partition_size": 8
ml-512-node-033:     }, 
ml-512-node-033:     "tensorboard": {
ml-512-node-033:         "enabled": false, 
ml-512-node-033:         "output_path": "step1_tensorboard/ds_tensorboard_logs/", 
ml-512-node-033:         "job_name": "step1_model_tensorboard"
ml-512-node-033:     }
ml-512-node-033: }
ml-512-node-033: ***** Running training *****
ml-512-node-033: Beginning of Epoch 1/100, Total Micro Batches 7
ml-512-node-033: [2024-07-08 06:01:47,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-033: [2024-07-08 06:01:47,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-033: [2024-07-08 06:01:47,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-033: [2024-07-08 06:01:47,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-033: [2024-07-08 06:01:47,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-033: [2024-07-08 06:01:47,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-033: [2024-07-08 06:01:47,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-033: [2024-07-08 06:01:47,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-033: [2024-07-08 06:01:47,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-033: [2024-07-08 06:01:47,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-033: [2024-07-08 06:01:47,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-033: [2024-07-08 06:01:47,246] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 65536, reducing to 32768.0
ml-512-node-033: [2024-07-08 06:01:47,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-040: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:47,249] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-033: [2024-07-08 06:01:47,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-034: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-033: [2024-07-08 06:01:47,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:47,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-036: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-041: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-037: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-037: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-037: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-038: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-039: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-039: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-045: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-045: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-039: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-039: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-048: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-033: [2024-07-08 06:01:47,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-039: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-036: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-041: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-036: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-041: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-048: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-039: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-042: [2024-07-08 06:01:47,249] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-042: [2024-07-08 06:01:47,249] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-035: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-042: [2024-07-08 06:01:47,249] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-038: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:47,249] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-042: [2024-07-08 06:01:47,249] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:47,249] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-045: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:47,249] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-047: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-037: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-037: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-047: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-044: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:47,249] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-041: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-048: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-037: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-035: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-035: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-035: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-043: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-035: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-048: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-048: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-048: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-048: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-048: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-048: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-048: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-046: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-037: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-043: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-043: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-040: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-042: [2024-07-08 06:01:47,249] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-036: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-036: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-036: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-036: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-036: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-035: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-035: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-044: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-035: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-039: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-039: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-035: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-039: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-035: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-039: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-035: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-035: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-035: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-046: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-046: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-046: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-046: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-046: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-046: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-046: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-046: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-046: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-046: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-046: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-036: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-036: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-045: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-044: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-040: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-040: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-036: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-036: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-044: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-034: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-040: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-040: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-036: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-036: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-038: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-043: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-048: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-043: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-042: [2024-07-08 06:01:47,249] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-038: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-041: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-048: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-038: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-047: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-047: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-045: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:47,249] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-042: [2024-07-08 06:01:47,249] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-045: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-042: [2024-07-08 06:01:47,249] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-047: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-042: [2024-07-08 06:01:47,249] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-040: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-040: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-042: [2024-07-08 06:01:47,249] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-040: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-040: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-040: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-047: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-047: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-047: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-034: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-034: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-034: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-040: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-040: [2024-07-08 06:01:47,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 06:01:47,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-036: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-036: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-036: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-036: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-036: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-036: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-036: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-036: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-036: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-044: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-044: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-044: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-047: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-047: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-044: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-044: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-044: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-047: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-047: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-044: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-044: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-043: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-044: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-044: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-044: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-044: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-044: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-033: [2024-07-08 06:01:47,431] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-044: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-045: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-045: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-045: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-047: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-043: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-039: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-034: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-040: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-035: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-045: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-048: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-048: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-035: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-035: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-035: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-043: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-045: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-047: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-040: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-040: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-034: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-045: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-045: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-040: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-045: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-033: [2024-07-08 06:01:47,431] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-034: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:47,433] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-041: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-043: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-048: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-048: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-037: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-037: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-047: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-047: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-041: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-037: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-045: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:47,431] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-037: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:47,431] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-033: [2024-07-08 06:01:47,431] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-033: [2024-07-08 06:01:47,431] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: [2024-07-08 06:01:47,431] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-045: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-040: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: [2024-07-08 06:01:47,431] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: [2024-07-08 06:01:47,431] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-040: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:47,431] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-034: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-040: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-040: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-040: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-041: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-040: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-041: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:47,433] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-045: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-038: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-038: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-048: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-043: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-041: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-035: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:47,431] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-034: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-034: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-041: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-048: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:47,433] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-034: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-039: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-033: [2024-07-08 06:01:47,431] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-048: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-048: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-035: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-043: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-043: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-043: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-043: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:47,433] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-042: [2024-07-08 06:01:47,433] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-042: [2024-07-08 06:01:47,433] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-042: [2024-07-08 06:01:47,433] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-039: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-039: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-035: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-043: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-043: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-046: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-046: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-041: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-046: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-041: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:47,433] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-042: [2024-07-08 06:01:47,433] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-042: [2024-07-08 06:01:47,433] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-033: [2024-07-08 06:01:47,431] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: [2024-07-08 06:01:47,431] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-042: [2024-07-08 06:01:47,433] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: [2024-07-08 06:01:47,431] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 32768.0, reducing to 16384.0
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-033: [2024-07-08 06:01:47,431] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-039: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-043: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-043: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-043: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-035: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-046: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-038: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-038: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: [2024-07-08 06:01:47,431] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-038: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-038: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-038: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:47,433] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-042: [2024-07-08 06:01:47,433] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-042: [2024-07-08 06:01:47,433] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-046: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-046: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-042: [2024-07-08 06:01:47,433] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-041: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-042: [2024-07-08 06:01:47,434] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-041: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-039: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-041: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-041: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-038: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-038: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-038: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-038: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-038: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-038: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-038: [2024-07-08 06:01:47,435] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-047: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-047: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-047: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-047: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-047: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-047: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-047: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-047: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-044: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-044: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-044: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-044: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-044: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-044: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-044: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-044: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-039: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-039: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-039: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-039: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-039: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-039: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-039: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-039: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-039: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-039: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-039: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-039: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-039: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-039: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-039: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-039: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-041: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:47,617] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-033: [2024-07-08 06:01:47,617] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-037: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:47,617] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-033: [2024-07-08 06:01:47,617] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-033: [2024-07-08 06:01:47,617] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-048: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:47,617] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-038: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-038: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:47,617] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 06:01:47,619] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-033: [2024-07-08 06:01:47,617] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 06:01:47,619] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-033: [2024-07-08 06:01:47,617] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-034: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-036: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-033: [2024-07-08 06:01:47,617] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-037: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-046: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:47,619] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-036: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-036: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-036: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-038: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-045: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-046: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-048: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-046: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-046: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-033: [2024-07-08 06:01:47,617] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-048: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:47,619] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-035: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-045: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-037: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-037: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-037: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-042: [2024-07-08 06:01:47,619] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-037: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-042: [2024-07-08 06:01:47,619] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 06:01:47,619] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-033: [2024-07-08 06:01:47,617] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-042: [2024-07-08 06:01:47,619] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-033: [2024-07-08 06:01:47,617] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-034: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-041: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-034: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-042: [2024-07-08 06:01:47,619] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-034: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:47,619] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-040: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-037: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-034: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-037: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-034: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-037: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-037: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-037: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-033: [2024-07-08 06:01:47,617] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-041: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:47,617] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-042: [2024-07-08 06:01:47,619] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-033: [2024-07-08 06:01:47,617] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-038: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 06:01:47,619] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-034: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-034: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-036: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-042: [2024-07-08 06:01:47,619] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-041: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-033: [2024-07-08 06:01:47,617] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 16384.0, reducing to 8192.0
ml-512-node-042: [2024-07-08 06:01:47,619] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-042: [2024-07-08 06:01:47,619] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 06:01:47,619] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-041: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-041: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-041: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-045: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-045: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-041: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-048: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-045: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-048: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-041: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-041: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-046: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-040: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-046: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-048: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-048: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-048: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-048: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-048: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-048: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-046: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-038: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-035: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-045: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-041: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-041: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-046: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-040: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-041: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-038: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-040: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-040: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-046: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-036: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-040: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: [2024-07-08 06:01:47,620] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-035: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-036: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-046: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-046: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-035: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-035: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-035: [2024-07-08 06:01:47,621] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-043: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-043: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-043: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-043: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-043: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-043: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-043: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-043: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-033: [2024-07-08 06:01:47,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-033: [2024-07-08 06:01:47,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-033: [2024-07-08 06:01:47,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-040: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-039: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-040: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-037: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-040: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-040: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-033: [2024-07-08 06:01:47,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-042: [2024-07-08 06:01:47,802] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-037: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-048: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-037: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-048: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-046: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-036: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-034: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-045: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-034: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-044: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-039: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-044: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-044: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-035: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-039: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:47,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-035: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-033: [2024-07-08 06:01:47,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-042: [2024-07-08 06:01:47,802] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-033: [2024-07-08 06:01:47,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-035: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:47,802] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-033: [2024-07-08 06:01:47,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-033: [2024-07-08 06:01:47,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-033: [2024-07-08 06:01:47,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-033: [2024-07-08 06:01:47,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-033: [2024-07-08 06:01:47,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-033: [2024-07-08 06:01:47,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-033: [2024-07-08 06:01:47,800] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 8192.0, reducing to 4096.0
ml-512-node-033: [2024-07-08 06:01:47,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-033: [2024-07-08 06:01:47,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-033: [2024-07-08 06:01:47,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-044: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-045: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-035: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: [2024-07-08 06:01:47,802] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-038: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-044: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:47,802] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-038: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-047: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-038: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-035: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-047: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-042: [2024-07-08 06:01:47,802] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-035: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-035: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-038: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-039: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-039: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-038: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-034: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:47,802] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-041: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-042: [2024-07-08 06:01:47,802] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-041: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-042: [2024-07-08 06:01:47,802] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-035: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:47,802] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: [2024-07-08 06:01:47,802] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: [2024-07-08 06:01:47,802] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-048: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-035: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-048: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-036: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-038: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-045: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-042: [2024-07-08 06:01:47,802] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-042: [2024-07-08 06:01:47,802] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-039: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-045: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:47,802] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-045: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-041: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-040: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-040: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-038: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-042: [2024-07-08 06:01:47,802] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-035: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-038: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-034: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-034: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-045: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-040: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-037: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-048: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-034: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-034: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-034: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-036: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-036: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-036: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-041: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-048: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-040: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-041: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-035: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-038: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-036: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-045: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-034: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-045: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-041: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-034: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-037: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-041: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-036: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-037: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-038: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-035: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-038: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-034: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-045: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-045: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-040: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-034: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-045: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-034: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-034: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-045: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-034: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-045: [2024-07-08 06:01:47,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-040: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-040: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-040: [2024-07-08 06:01:47,803] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 06:01:47,808] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-039: [2024-07-08 06:01:47,808] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-043: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-036: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-036: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-036: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-036: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-044: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-044: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-043: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-048: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-036: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-036: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-036: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-039: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-036: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-044: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-044: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: [2024-07-08 06:01:47,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-034: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-034: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-034: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-034: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-035: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-035: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-035: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-035: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-033: [2024-07-08 06:01:47,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:47,987] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-035: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-033: [2024-07-08 06:01:47,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-036: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-047: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-036: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-047: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-047: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-047: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-047: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-047: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-039: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-039: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-039: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-039: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-039: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-039: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-044: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-044: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-044: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-046: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-033: [2024-07-08 06:01:47,984] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-044: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: [2024-07-08 06:01:47,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-038: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-037: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-047: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-035: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-039: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-037: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-042: [2024-07-08 06:01:47,987] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-046: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:47,987] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-033: [2024-07-08 06:01:47,984] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-043: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: [2024-07-08 06:01:47,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-033: [2024-07-08 06:01:47,984] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-035: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-045: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-045: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-045: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-045: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-045: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: [2024-07-08 06:01:47,984] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-043: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-036: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-036: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-036: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-042: [2024-07-08 06:01:47,987] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-042: [2024-07-08 06:01:47,987] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:47,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-033: [2024-07-08 06:01:47,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-033: [2024-07-08 06:01:47,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-033: [2024-07-08 06:01:47,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: [2024-07-08 06:01:47,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: [2024-07-08 06:01:47,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: [2024-07-08 06:01:47,985] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 4096.0, reducing to 2048.0
ml-512-node-033: [2024-07-08 06:01:47,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-035: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-035: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-035: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-035: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-035: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-039: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-039: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-039: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-043: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-043: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-043: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-043: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-043: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-043: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-045: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-045: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-042: [2024-07-08 06:01:47,987] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-042: [2024-07-08 06:01:47,987] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-042: [2024-07-08 06:01:47,987] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-042: [2024-07-08 06:01:47,987] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-037: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-042: [2024-07-08 06:01:47,987] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-042: [2024-07-08 06:01:47,987] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-042: [2024-07-08 06:01:47,987] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-042: [2024-07-08 06:01:47,987] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-042: [2024-07-08 06:01:47,987] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-042: [2024-07-08 06:01:47,987] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-042: [2024-07-08 06:01:47,987] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-041: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-041: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-041: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-041: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-040: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-040: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-034: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-038: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-040: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-038: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-038: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-034: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-034: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-046: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-034: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-047: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-047: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-046: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-034: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-034: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-034: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-038: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-034: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-034: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-040: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-040: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-040: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-048: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-048: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-048: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-048: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-038: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-040: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-038: [2024-07-08 06:01:47,989] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-040: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-041: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-040: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: [2024-07-08 06:01:47,988] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-043: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-043: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-043: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-043: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-043: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-043: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-043: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-043: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-043: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-043: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: [2024-07-08 06:01:48,171] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-042: [2024-07-08 06:01:48,171] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-042: [2024-07-08 06:01:48,171] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-042: [2024-07-08 06:01:48,171] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-042: [2024-07-08 06:01:48,171] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-042: [2024-07-08 06:01:48,171] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-042: [2024-07-08 06:01:48,171] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: [2024-07-08 06:01:48,171] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: [2024-07-08 06:01:48,171] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: [2024-07-08 06:01:48,171] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: [2024-07-08 06:01:48,171] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: [2024-07-08 06:01:48,171] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: [2024-07-08 06:01:48,168] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:48,171] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-037: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-033: [2024-07-08 06:01:48,168] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-042: [2024-07-08 06:01:48,171] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-047: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-033: [2024-07-08 06:01:48,168] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-047: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-047: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-047: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-047: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-047: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-044: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-039: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-039: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-039: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-039: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-047: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-041: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-039: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-042: [2024-07-08 06:01:48,171] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-042: [2024-07-08 06:01:48,171] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: [2024-07-08 06:01:48,168] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: [2024-07-08 06:01:48,168] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: [2024-07-08 06:01:48,168] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-033: [2024-07-08 06:01:48,168] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: [2024-07-08 06:01:48,168] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-033: [2024-07-08 06:01:48,168] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: [2024-07-08 06:01:48,168] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-033: [2024-07-08 06:01:48,168] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-047: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-039: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: [2024-07-08 06:01:48,168] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: [2024-07-08 06:01:48,168] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:48,168] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-044: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-044: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:48,168] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-041: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-044: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: [2024-07-08 06:01:48,168] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:48,169] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 2048.0, reducing to 1024.0
ml-512-node-044: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-047: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-044: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-044: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-047: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-036: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-047: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-044: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-044: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-043: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-041: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-043: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-036: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-041: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-047: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-044: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-038: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-040: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-040: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-040: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-040: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-040: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-036: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-036: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-040: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-043: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-043: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-043: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-040: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-046: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-046: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-046: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-046: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-045: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-046: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-045: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-046: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-048: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-044: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-044: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-041: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-041: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-048: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-034: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-034: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-034: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-034: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-034: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-041: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-034: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-041: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-034: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-034: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-034: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-034: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-044: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-034: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-044: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-034: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-044: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-034: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-037: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-037: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-035: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-035: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-036: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-038: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-038: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-038: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-038: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-045: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-045: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-045: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-045: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-045: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-035: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-045: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-045: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-045: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-045: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-045: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-036: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-048: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-037: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-038: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-045: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-036: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-035: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-037: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-048: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-036: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-048: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-035: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-036: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-036: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-038: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-036: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-035: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-048: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-048: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-048: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-048: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-048: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-048: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-048: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-037: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-048: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-048: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-038: [2024-07-08 06:01:48,172] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: [2024-07-08 06:01:48,173] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-041: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-041: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-041: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-041: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-041: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-041: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-041: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-041: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-041: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-041: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-041: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-041: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-041: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-041: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-041: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-033: [2024-07-08 06:01:48,352] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 06:01:48,352] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-039: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-039: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-039: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-043: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:48,355] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-037: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-039: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-047: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-039: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-036: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-046: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-046: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-036: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-036: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-046: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-036: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 06:01:48,352] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-036: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-043: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:48,352] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-044: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-034: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-034: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-034: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-034: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:48,352] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 06:01:48,352] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 06:01:48,352] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 06:01:48,352] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-034: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-043: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-034: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-046: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-042: [2024-07-08 06:01:48,355] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-046: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-034: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:48,355] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-042: [2024-07-08 06:01:48,355] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-042: [2024-07-08 06:01:48,355] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:48,355] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 06:01:48,352] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 06:01:48,352] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 1024.0, reducing to 512.0
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-038: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:48,352] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-046: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 06:01:48,352] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 06:01:48,352] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:48,355] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:48,352] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-048: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-043: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-034: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-036: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-036: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 06:01:48,352] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-033: [2024-07-08 06:01:48,352] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 06:01:48,352] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-033: Beginning of Epoch 2/100, Total Micro Batches 7
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-044: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-044: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-044: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-044: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-044: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-044: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-042: [2024-07-08 06:01:48,355] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-044: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-042: [2024-07-08 06:01:48,355] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-047: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-047: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-047: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-047: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-047: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-047: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-044: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-044: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-047: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-036: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-044: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-040: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-039: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-034: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-039: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-043: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-043: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-039: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-039: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-035: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-036: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-039: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-042: [2024-07-08 06:01:48,355] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-036: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-042: [2024-07-08 06:01:48,355] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-034: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-036: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-036: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-036: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-044: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-039: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-039: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-039: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-039: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-044: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-040: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-047: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-040: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-038: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-035: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-040: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-037: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:48,355] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-038: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-035: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-035: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-038: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-040: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-042: [2024-07-08 06:01:48,355] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-040: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-047: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-047: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-034: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-034: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-037: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-048: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-042: [2024-07-08 06:01:48,355] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-034: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-040: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:48,355] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-040: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-040: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-040: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-048: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-037: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-045: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-038: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-042: [2024-07-08 06:01:48,355] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-040: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-038: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-045: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-045: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-048: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-048: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: [2024-07-08 06:01:48,356] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-037: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-037: [2024-07-08 06:01:48,357] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-044: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-044: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-044: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-044: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-044: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-044: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-044: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-044: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-044: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-034: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-034: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-034: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-034: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-034: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-034: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-034: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-034: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-047: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-046: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-046: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-046: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-043: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-043: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-048: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-046: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-046: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-043: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-046: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-041: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-035: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-046: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-043: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-037: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-036: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:48,537] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-048: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-048: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-046: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-046: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-033: [2024-07-08 06:01:48,537] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-043: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-047: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-043: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-048: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-036: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-048: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-043: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-035: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-043: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-041: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-043: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-046: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-043: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-041: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-036: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:48,537] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-048: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-048: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-041: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-041: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-039: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-043: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-041: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-045: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-041: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:48,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-048: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-041: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-042: [2024-07-08 06:01:48,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-048: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: [2024-07-08 06:01:48,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-048: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-048: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-042: [2024-07-08 06:01:48,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: [2024-07-08 06:01:48,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-038: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-033: [2024-07-08 06:01:48,537] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-038: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-041: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-043: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-046: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-048: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-033: [2024-07-08 06:01:48,537] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:48,537] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-048: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-045: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-045: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-033: [2024-07-08 06:01:48,537] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-040: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-035: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: [2024-07-08 06:01:48,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-042: [2024-07-08 06:01:48,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-038: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-042: [2024-07-08 06:01:48,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: [2024-07-08 06:01:48,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-039: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:48,537] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-033: [2024-07-08 06:01:48,537] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-038: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-033: [2024-07-08 06:01:48,537] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-035: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-038: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-033: [2024-07-08 06:01:48,537] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 512.0, reducing to 256.0
ml-512-node-042: [2024-07-08 06:01:48,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:48,537] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-035: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-037: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:48,537] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-033: [2024-07-08 06:01:48,537] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-033: [2024-07-08 06:01:48,537] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-033: [2024-07-08 06:01:48,537] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-033: [2024-07-08 06:01:48,537] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: [2024-07-08 06:01:48,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: [2024-07-08 06:01:48,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: [2024-07-08 06:01:48,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-038: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: [2024-07-08 06:01:48,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-037: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-035: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-038: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: [2024-07-08 06:01:48,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-035: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:48,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-040: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-035: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-037: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-035: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-037: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-035: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-037: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-038: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-037: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-040: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-038: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-038: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: [2024-07-08 06:01:48,540] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-035: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-037: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-037: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-037: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-037: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-037: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-037: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-037: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-037: [2024-07-08 06:01:48,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-044: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-044: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-044: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-044: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-044: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-044: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-044: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-044: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-034: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-034: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-034: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-034: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-034: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-034: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-034: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-034: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-034: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-041: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-041: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-041: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-047: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-041: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-047: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-047: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-034: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-047: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-047: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-047: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-037: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-041: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-034: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-040: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:48,723] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-040: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-040: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-040: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-040: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-047: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-034: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-034: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-047: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-034: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-041: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-038: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-038: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-038: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-041: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-039: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-035: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-033: [2024-07-08 06:01:48,720] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-048: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:48,723] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-036: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-040: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: [2024-07-08 06:01:48,723] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-040: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-038: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-037: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-041: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-037: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-041: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: [2024-07-08 06:01:48,723] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-041: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-036: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-041: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-036: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-039: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: [2024-07-08 06:01:48,723] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-038: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: [2024-07-08 06:01:48,723] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-038: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-038: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-038: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-046: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-046: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-046: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-042: [2024-07-08 06:01:48,723] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-042: [2024-07-08 06:01:48,723] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-046: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: [2024-07-08 06:01:48,723] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-045: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-046: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-045: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-038: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-042: [2024-07-08 06:01:48,723] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-047: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-045: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-035: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-035: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-047: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:48,723] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: [2024-07-08 06:01:48,723] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-047: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:48,723] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-047: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-046: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-040: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-046: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-038: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: [2024-07-08 06:01:48,723] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-047: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-037: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-046: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-047: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-042: [2024-07-08 06:01:48,723] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-046: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: [2024-07-08 06:01:48,723] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-038: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-045: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-043: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-045: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-045: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-035: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-043: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-046: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-045: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-037: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-037: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-038: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-038: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-037: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-037: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-045: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-035: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-037: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-037: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-033: [2024-07-08 06:01:48,720] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-045: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-039: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-037: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-033: [2024-07-08 06:01:48,720] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-033: [2024-07-08 06:01:48,720] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-033: [2024-07-08 06:01:48,720] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:48,720] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-048: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-036: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-036: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-033: [2024-07-08 06:01:48,720] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-036: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-033: [2024-07-08 06:01:48,720] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-039: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:48,720] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-036: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-048: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-036: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:48,720] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 256.0, reducing to 128.0
ml-512-node-036: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-033: [2024-07-08 06:01:48,720] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-036: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-036: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-033: [2024-07-08 06:01:48,720] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-033: [2024-07-08 06:01:48,720] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-036: [2024-07-08 06:01:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-039: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-033: [2024-07-08 06:01:48,720] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-033: [2024-07-08 06:01:48,720] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-048: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-048: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-033: [2024-07-08 06:01:48,720] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-033: [2024-07-08 06:01:48,720] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-048: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: [2024-07-08 06:01:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-044: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-044: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-044: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-044: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-044: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-046: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-043: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-043: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-046: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-043: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-046: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-046: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-043: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-046: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-043: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-043: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-043: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-046: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-046: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-046: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-046: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-044: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-046: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-045: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-038: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-038: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-038: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: [2024-07-08 06:01:48,907] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-043: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-044: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-046: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-046: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-046: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-046: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-038: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-038: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-047: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-047: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-047: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-047: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-047: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-047: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-047: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-036: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-043: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: [2024-07-08 06:01:48,907] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-041: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-034: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-036: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-042: [2024-07-08 06:01:48,907] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-042: [2024-07-08 06:01:48,907] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-042: [2024-07-08 06:01:48,907] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: [2024-07-08 06:01:48,907] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: [2024-07-08 06:01:48,907] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-037: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-037: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-037: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-037: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-043: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-037: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-037: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-042: [2024-07-08 06:01:48,907] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-042: [2024-07-08 06:01:48,907] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-038: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-038: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:48,907] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-042: [2024-07-08 06:01:48,907] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-038: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-047: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-042: [2024-07-08 06:01:48,907] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-042: [2024-07-08 06:01:48,907] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-047: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: [2024-07-08 06:01:48,907] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-034: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-034: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-045: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-035: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-033: [2024-07-08 06:01:48,905] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-035: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-035: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-035: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-035: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-035: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-041: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-035: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-034: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-034: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-035: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-034: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-034: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-038: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:48,907] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-047: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: [2024-07-08 06:01:48,907] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-045: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-035: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-047: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:48,905] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-041: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 06:01:48,905] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-034: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-036: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-038: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-038: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-038: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-038: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 06:01:48,905] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-035: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 06:01:48,905] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-035: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 06:01:48,905] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-045: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-041: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-037: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 06:01:48,905] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-037: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-039: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:48,905] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 06:01:48,905] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-037: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-040: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-033: [2024-07-08 06:01:48,905] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 06:01:48,905] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-033: [2024-07-08 06:01:48,905] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 128.0, reducing to 64.0
ml-512-node-037: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-040: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 06:01:48,905] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 06:01:48,905] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 06:01:48,905] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:48,905] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-039: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-037: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:48,905] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-037: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-037: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-040: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-040: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-040: [2024-07-08 06:01:48,908] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-033: [2024-07-08 06:01:48,905] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=10, lr=[0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-048: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:48,910] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-039: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-048: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-033: [2024-07-08 06:01:48,905] [INFO] [timer.py:258:stop] epoch=0/micro_step=10/global_step=10, RunningAvgSamplesPerSec=16736.10847834526, CurrSamplesPerSec=16693.72563520207, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-048: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-048: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-048: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-048: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-048: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-048: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-048: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-048: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-048: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-048: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-048: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-048: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-048: [2024-07-08 06:01:48,909] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-043: [2024-07-08 06:01:49,091] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-043: [2024-07-08 06:01:49,091] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-043: [2024-07-08 06:01:49,091] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-043: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-043: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-043: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-043: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-043: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-044: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-044: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-043: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-043: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-043: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-044: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-044: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-044: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-043: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-043: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-043: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-043: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-043: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-044: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-044: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-036: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-036: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-036: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-036: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-036: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-036: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-036: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-036: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-047: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-040: [2024-07-08 06:01:49,091] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-040: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-041: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-037: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-040: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-040: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-040: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-040: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-033: [2024-07-08 06:01:49,088] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-048: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-040: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-048: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-047: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-048: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-037: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-037: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-048: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-048: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-047: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-040: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-048: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-037: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: [2024-07-08 06:01:49,088] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-040: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-037: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-040: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-047: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-048: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-040: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-048: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:49,090] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-035: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-038: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-046: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-040: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-040: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-041: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-040: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-048: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-048: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: [2024-07-08 06:01:49,090] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-035: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-034: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-034: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-045: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-046: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-042: [2024-07-08 06:01:49,090] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: [2024-07-08 06:01:49,088] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-041: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-034: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-046: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-033: [2024-07-08 06:01:49,088] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-046: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-033: [2024-07-08 06:01:49,088] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-045: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-035: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-039: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-039: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-039: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-039: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-039: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-047: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: [2024-07-08 06:01:49,090] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-042: [2024-07-08 06:01:49,090] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-033: [2024-07-08 06:01:49,088] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-038: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-039: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-038: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-038: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: [2024-07-08 06:01:49,090] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-042: [2024-07-08 06:01:49,091] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-035: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: [2024-07-08 06:01:49,091] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-038: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:49,091] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-038: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: [2024-07-08 06:01:49,091] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: [2024-07-08 06:01:49,091] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-042: [2024-07-08 06:01:49,091] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: [2024-07-08 06:01:49,091] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: [2024-07-08 06:01:49,091] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:49,091] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-045: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-045: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-033: [2024-07-08 06:01:49,088] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: [2024-07-08 06:01:49,091] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: [2024-07-08 06:01:49,088] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-035: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-046: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-035: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-033: [2024-07-08 06:01:49,088] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-039: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-034: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-046: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-039: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-034: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-039: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-041: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-041: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-039: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: [2024-07-08 06:01:49,088] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 64.0, reducing to 32.0
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-046: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-034: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-039: [2024-07-08 06:01:49,093] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: [2024-07-08 06:01:49,088] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-033: [2024-07-08 06:01:49,088] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-045: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-046: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-033: [2024-07-08 06:01:49,088] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-035: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: [2024-07-08 06:01:49,088] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-033: [2024-07-08 06:01:49,088] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-045: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-035: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-035: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-035: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:49,088] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-045: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-035: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: [2024-07-08 06:01:49,088] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-046: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-046: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-046: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-046: [2024-07-08 06:01:49,092] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-038: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-038: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-038: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-038: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-043: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-043: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-043: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-043: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-043: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-043: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-043: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-043: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-043: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-038: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-043: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-038: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-043: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-043: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-043: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-043: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-038: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-043: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-043: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-044: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-044: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-044: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-044: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-044: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-044: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-044: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-036: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-036: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-036: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-036: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-036: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-036: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-047: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-047: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-036: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-047: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-047: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-047: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-036: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-036: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-047: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-047: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-047: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-034: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-034: [2024-07-08 06:01:49,276] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-047: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-047: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-047: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-034: [2024-07-08 06:01:49,276] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-034: [2024-07-08 06:01:49,276] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-034: [2024-07-08 06:01:49,276] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-034: [2024-07-08 06:01:49,276] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-034: [2024-07-08 06:01:49,276] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-040: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-037: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:49,271] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-034: [2024-07-08 06:01:49,276] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:49,271] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-033: [2024-07-08 06:01:49,271] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-033: [2024-07-08 06:01:49,271] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:01:49,276] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-039: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-047: [2024-07-08 06:01:49,276] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-039: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-039: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-039: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-034: [2024-07-08 06:01:49,276] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-039: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:01:49,276] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-034: [2024-07-08 06:01:49,276] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-034: [2024-07-08 06:01:49,276] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-034: [2024-07-08 06:01:49,276] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-034: [2024-07-08 06:01:49,276] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-034: [2024-07-08 06:01:49,276] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-035: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-035: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-035: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-035: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-040: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-037: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-037: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-040: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-037: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-045: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-045: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-037: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-037: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-035: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-041: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: [2024-07-08 06:01:49,271] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-039: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-041: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-035: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-042: [2024-07-08 06:01:49,274] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-048: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-041: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-040: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:49,271] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-042: [2024-07-08 06:01:49,274] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-042: [2024-07-08 06:01:49,274] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-046: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-046: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-042: [2024-07-08 06:01:49,274] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-037: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-033: [2024-07-08 06:01:49,271] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-033: [2024-07-08 06:01:49,271] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-037: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:49,271] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-035: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-046: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-039: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:49,271] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-041: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-042: [2024-07-08 06:01:49,274] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:49,271] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 32.0, reducing to 16.0
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-039: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: [2024-07-08 06:01:49,271] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-035: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-039: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-041: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-035: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-040: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-041: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-042: [2024-07-08 06:01:49,274] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-042: [2024-07-08 06:01:49,274] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: [2024-07-08 06:01:49,271] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:01:49,274] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-033: [2024-07-08 06:01:49,271] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:01:49,271] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-042: [2024-07-08 06:01:49,274] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-042: [2024-07-08 06:01:49,274] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-042: [2024-07-08 06:01:49,274] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-042: [2024-07-08 06:01:49,274] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-035: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-035: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-037: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-037: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-041: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-040: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-040: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-039: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-041: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: [2024-07-08 06:01:49,271] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: [2024-07-08 06:01:49,271] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-041: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-042: [2024-07-08 06:01:49,274] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-046: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-039: [2024-07-08 06:01:49,276] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-045: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-035: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-037: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-041: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-042: [2024-07-08 06:01:49,274] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-046: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-035: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-048: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-048: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-048: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-037: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-048: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:01:49,276] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-045: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-045: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-045: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-042: [2024-07-08 06:01:49,274] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-042: [2024-07-08 06:01:49,274] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-048: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: [2024-07-08 06:01:49,275] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: [2024-07-08 06:01:49,276] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-048: [2024-07-08 06:01:49,276] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: Beginning of Epoch 3/100, Total Micro Batches 7
ml-512-node-033: [2024-07-08 06:01:50,953] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=12, lr=[8.000000000000001e-11, 8.000000000000001e-11], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 06:01:50,957] [INFO] [timer.py:258:stop] epoch=0/micro_step=20/global_step=20, RunningAvgSamplesPerSec=15736.172138600956, CurrSamplesPerSec=14832.190516534823, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-033: Beginning of Epoch 4/100, Total Micro Batches 7
ml-512-node-033: Beginning of Epoch 5/100, Total Micro Batches 7
ml-512-node-033: [2024-07-08 06:01:53,024] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=12, lr=[9.996683549418964e-11, 9.996683549418964e-11], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 06:01:53,029] [INFO] [timer.py:258:stop] epoch=0/micro_step=30/global_step=30, RunningAvgSamplesPerSec=15420.261657649291, CurrSamplesPerSec=14923.340685610247, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-033: Beginning of Epoch 6/100, Total Micro Batches 7
ml-512-node-033: [2024-07-08 06:01:55,095] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=12, lr=[9.983218008802648e-11, 9.983218008802648e-11], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 06:01:55,099] [INFO] [timer.py:258:stop] epoch=0/micro_step=40/global_step=40, RunningAvgSamplesPerSec=15273.31994756067, CurrSamplesPerSec=14901.180640460743, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-033: Beginning of Epoch 7/100, Total Micro Batches 7
ml-512-node-033: Beginning of Epoch 8/100, Total Micro Batches 7
ml-512-node-033: [2024-07-08 06:01:57,168] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=12, lr=[9.959423987893087e-11, 9.959423987893087e-11], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 06:01:57,172] [INFO] [timer.py:258:stop] epoch=0/micro_step=50/global_step=50, RunningAvgSamplesPerSec=15187.79459142132, CurrSamplesPerSec=14899.19911193853, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-033: Beginning of Epoch 9/100, Total Micro Batches 7
ml-512-node-033: [2024-07-08 06:01:59,232] [INFO] [logging.py:96:log_dist] [Rank 0] step=60, skipped=12, lr=[9.925350803432112e-11, 9.925350803432112e-11], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 06:01:59,237] [INFO] [timer.py:258:stop] epoch=0/micro_step=60/global_step=60, RunningAvgSamplesPerSec=15141.55729536536, CurrSamplesPerSec=14899.268025823281, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-033: Beginning of Epoch 10/100, Total Micro Batches 7
ml-512-node-033: [2024-07-08 06:02:01,297] [INFO] [logging.py:96:log_dist] [Rank 0] step=70, skipped=12, lr=[9.881069077297723e-11, 9.881069077297723e-11], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 06:02:01,301] [INFO] [timer.py:258:stop] epoch=0/micro_step=70/global_step=70, RunningAvgSamplesPerSec=15108.905699865918, CurrSamplesPerSec=14907.387095206692, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-033: Beginning of Epoch 11/100, Total Micro Batches 7
ml-512-node-033: Beginning of Epoch 12/100, Total Micro Batches 7
ml-512-node-033: [2024-07-08 06:02:03,362] [INFO] [logging.py:96:log_dist] [Rank 0] step=80, skipped=12, lr=[9.826670590129441e-11, 9.826670590129441e-11], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 06:02:03,366] [INFO] [timer.py:258:stop] epoch=0/micro_step=80/global_step=80, RunningAvgSamplesPerSec=15085.803398796459, CurrSamplesPerSec=14895.461488840747, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-033: Beginning of Epoch 13/100, Total Micro Batches 7
ml-512-node-033: [2024-07-08 06:02:05,425] [INFO] [logging.py:96:log_dist] [Rank 0] step=90, skipped=12, lr=[9.762268091098925e-11, 9.762268091098925e-11], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 06:02:05,429] [INFO] [timer.py:258:stop] epoch=0/micro_step=90/global_step=90, RunningAvgSamplesPerSec=15067.718622736671, CurrSamplesPerSec=14894.204553257157, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-033: Beginning of Epoch 14/100, Total Micro Batches 7
ml-512-node-033: Beginning of Epoch 15/100, Total Micro Batches 7
ml-512-node-033: [2024-07-08 06:02:07,490] [INFO] [logging.py:96:log_dist] [Rank 0] step=100, skipped=12, lr=[9.687995064220102e-11, 9.687995064220102e-11], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 06:02:07,494] [INFO] [timer.py:258:stop] epoch=0/micro_step=100/global_step=100, RunningAvgSamplesPerSec=15053.23767507898, CurrSamplesPerSec=14919.314537671411, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-033: Beginning of Epoch 16/100, Total Micro Batches 7
ml-512-node-033: [2024-07-08 06:02:09,554] [INFO] [logging.py:96:log_dist] [Rank 0] step=110, skipped=12, lr=[9.604005451683154e-11, 9.604005451683154e-11], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 06:02:09,558] [INFO] [timer.py:258:stop] epoch=0/micro_step=110/global_step=110, RunningAvgSamplesPerSec=15041.200120293335, CurrSamplesPerSec=14923.651808920207, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-033: ======================================================================
ml-512-node-033: Execution time: 20.6527 seconds for 100 steps
ml-512-node-033: Throughput: 14874.5843 samples/sec
ml-512-node-046: [2024-07-08 06:02:12,881] [INFO] [launch.py:351:main] Process 1054862 exits successfully.
ml-512-node-044: [2024-07-08 06:02:12,904] [INFO] [launch.py:351:main] Process 1053255 exits successfully.
ml-512-node-040: [2024-07-08 06:02:13,165] [INFO] [launch.py:351:main] Process 1110528 exits successfully.
ml-512-node-040: [2024-07-08 06:02:13,166] [INFO] [launch.py:351:main] Process 1110532 exits successfully.
ml-512-node-033: [2024-07-08 06:02:13,496] [INFO] [launch.py:351:main] Process 1066003 exits successfully.
ml-512-node-033: [2024-07-08 06:02:13,496] [INFO] [launch.py:351:main] Process 1066005 exits successfully.
ml-512-node-033: [2024-07-08 06:02:13,496] [INFO] [launch.py:351:main] Process 1066007 exits successfully.
ml-512-node-033: [2024-07-08 06:02:13,496] [INFO] [launch.py:351:main] Process 1066006 exits successfully.
ml-512-node-033: [2024-07-08 06:02:13,496] [INFO] [launch.py:351:main] Process 1066002 exits successfully.
ml-512-node-037: [2024-07-08 06:02:13,631] [INFO] [launch.py:351:main] Process 1059854 exits successfully.
ml-512-node-036: [2024-07-08 06:02:13,658] [INFO] [launch.py:351:main] Process 1055804 exits successfully.
ml-512-node-036: [2024-07-08 06:02:13,658] [INFO] [launch.py:351:main] Process 1055802 exits successfully.
ml-512-node-036: [2024-07-08 06:02:13,658] [INFO] [launch.py:351:main] Process 1055801 exits successfully.
ml-512-node-039: [2024-07-08 06:02:13,673] [INFO] [launch.py:351:main] Process 1142674 exits successfully.
ml-512-node-039: [2024-07-08 06:02:13,673] [INFO] [launch.py:351:main] Process 1142672 exits successfully.
ml-512-node-039: [2024-07-08 06:02:13,673] [INFO] [launch.py:351:main] Process 1142676 exits successfully.
ml-512-node-039: [2024-07-08 06:02:13,673] [INFO] [launch.py:351:main] Process 1142678 exits successfully.
ml-512-node-039: [2024-07-08 06:02:13,673] [INFO] [launch.py:351:main] Process 1142677 exits successfully.
ml-512-node-039: [2024-07-08 06:02:13,673] [INFO] [launch.py:351:main] Process 1142673 exits successfully.
ml-512-node-038: [2024-07-08 06:02:13,678] [INFO] [launch.py:351:main] Process 1055365 exits successfully.
ml-512-node-038: [2024-07-08 06:02:13,678] [INFO] [launch.py:351:main] Process 1055363 exits successfully.
ml-512-node-038: [2024-07-08 06:02:13,678] [INFO] [launch.py:351:main] Process 1055369 exits successfully.
ml-512-node-038: [2024-07-08 06:02:13,678] [INFO] [launch.py:351:main] Process 1055368 exits successfully.
ml-512-node-038: [2024-07-08 06:02:13,678] [INFO] [launch.py:351:main] Process 1055366 exits successfully.
ml-512-node-038: [2024-07-08 06:02:13,678] [INFO] [launch.py:351:main] Process 1055364 exits successfully.
ml-512-node-035: [2024-07-08 06:02:13,708] [INFO] [launch.py:351:main] Process 1063314 exits successfully.
ml-512-node-035: [2024-07-08 06:02:13,708] [INFO] [launch.py:351:main] Process 1063312 exits successfully.
ml-512-node-035: [2024-07-08 06:02:13,708] [INFO] [launch.py:351:main] Process 1063318 exits successfully.
ml-512-node-035: [2024-07-08 06:02:13,708] [INFO] [launch.py:351:main] Process 1063313 exits successfully.
ml-512-node-035: [2024-07-08 06:02:13,708] [INFO] [launch.py:351:main] Process 1063311 exits successfully.
ml-512-node-048: [2024-07-08 06:02:13,804] [INFO] [launch.py:351:main] Process 1053105 exits successfully.
ml-512-node-048: [2024-07-08 06:02:13,804] [INFO] [launch.py:351:main] Process 1053103 exits successfully.
ml-512-node-048: [2024-07-08 06:02:13,805] [INFO] [launch.py:351:main] Process 1053107 exits successfully.
ml-512-node-048: [2024-07-08 06:02:13,805] [INFO] [launch.py:351:main] Process 1053109 exits successfully.
ml-512-node-048: [2024-07-08 06:02:13,805] [INFO] [launch.py:351:main] Process 1053108 exits successfully.
ml-512-node-048: [2024-07-08 06:02:13,805] [INFO] [launch.py:351:main] Process 1053106 exits successfully.
ml-512-node-048: [2024-07-08 06:02:13,805] [INFO] [launch.py:351:main] Process 1053104 exits successfully.
ml-512-node-048: [2024-07-08 06:02:13,805] [INFO] [launch.py:351:main] Process 1053110 exits successfully.
ml-512-node-034: [2024-07-08 06:02:13,847] [INFO] [launch.py:351:main] Process 1056488 exits successfully.
ml-512-node-034: [2024-07-08 06:02:13,847] [INFO] [launch.py:351:main] Process 1056490 exits successfully.
ml-512-node-034: [2024-07-08 06:02:13,847] [INFO] [launch.py:351:main] Process 1056489 exits successfully.
ml-512-node-034: [2024-07-08 06:02:13,847] [INFO] [launch.py:351:main] Process 1056487 exits successfully.
ml-512-node-034: [2024-07-08 06:02:13,847] [INFO] [launch.py:351:main] Process 1056485 exits successfully.
ml-512-node-034: [2024-07-08 06:02:13,847] [INFO] [launch.py:351:main] Process 1056491 exits successfully.
ml-512-node-034: [2024-07-08 06:02:13,847] [INFO] [launch.py:351:main] Process 1056486 exits successfully.
ml-512-node-034: [2024-07-08 06:02:13,847] [INFO] [launch.py:351:main] Process 1056484 exits successfully.
ml-512-node-047: [2024-07-08 06:02:13,873] [INFO] [launch.py:351:main] Process 1056883 exits successfully.
ml-512-node-047: [2024-07-08 06:02:13,873] [INFO] [launch.py:351:main] Process 1056885 exits successfully.
ml-512-node-047: [2024-07-08 06:02:13,874] [INFO] [launch.py:351:main] Process 1056884 exits successfully.
ml-512-node-047: [2024-07-08 06:02:13,874] [INFO] [launch.py:351:main] Process 1056882 exits successfully.
ml-512-node-047: [2024-07-08 06:02:13,874] [INFO] [launch.py:351:main] Process 1056880 exits successfully.
ml-512-node-047: [2024-07-08 06:02:13,874] [INFO] [launch.py:351:main] Process 1056886 exits successfully.
ml-512-node-047: [2024-07-08 06:02:13,874] [INFO] [launch.py:351:main] Process 1056881 exits successfully.
ml-512-node-047: [2024-07-08 06:02:13,874] [INFO] [launch.py:351:main] Process 1056879 exits successfully.
ml-512-node-043: [2024-07-08 06:02:13,880] [INFO] [launch.py:351:main] Process 1058747 exits successfully.
ml-512-node-043: [2024-07-08 06:02:13,881] [INFO] [launch.py:351:main] Process 1058746 exits successfully.
ml-512-node-043: [2024-07-08 06:02:13,881] [INFO] [launch.py:351:main] Process 1058744 exits successfully.
ml-512-node-043: [2024-07-08 06:02:13,881] [INFO] [launch.py:351:main] Process 1058742 exits successfully.
ml-512-node-043: [2024-07-08 06:02:13,881] [INFO] [launch.py:351:main] Process 1058748 exits successfully.
ml-512-node-043: [2024-07-08 06:02:13,881] [INFO] [launch.py:351:main] Process 1058743 exits successfully.
ml-512-node-043: [2024-07-08 06:02:13,881] [INFO] [launch.py:351:main] Process 1058741 exits successfully.
ml-512-node-046: [2024-07-08 06:02:13,883] [INFO] [launch.py:351:main] Process 1054864 exits successfully.
ml-512-node-046: [2024-07-08 06:02:13,883] [INFO] [launch.py:351:main] Process 1054863 exits successfully.
ml-512-node-046: [2024-07-08 06:02:13,883] [INFO] [launch.py:351:main] Process 1054861 exits successfully.
ml-512-node-046: [2024-07-08 06:02:13,883] [INFO] [launch.py:351:main] Process 1054859 exits successfully.
ml-512-node-046: [2024-07-08 06:02:13,883] [INFO] [launch.py:351:main] Process 1054865 exits successfully.
ml-512-node-046: [2024-07-08 06:02:13,883] [INFO] [launch.py:351:main] Process 1054860 exits successfully.
ml-512-node-046: [2024-07-08 06:02:13,883] [INFO] [launch.py:351:main] Process 1054858 exits successfully.
ml-512-node-044: [2024-07-08 06:02:13,905] [INFO] [launch.py:351:main] Process 1053252 exits successfully.
ml-512-node-044: [2024-07-08 06:02:13,905] [INFO] [launch.py:351:main] Process 1053250 exits successfully.
ml-512-node-044: [2024-07-08 06:02:13,905] [INFO] [launch.py:351:main] Process 1053254 exits successfully.
ml-512-node-044: [2024-07-08 06:02:13,905] [INFO] [launch.py:351:main] Process 1053256 exits successfully.
ml-512-node-044: [2024-07-08 06:02:13,905] [INFO] [launch.py:351:main] Process 1053253 exits successfully.
ml-512-node-044: [2024-07-08 06:02:13,905] [INFO] [launch.py:351:main] Process 1053251 exits successfully.
ml-512-node-044: [2024-07-08 06:02:13,906] [INFO] [launch.py:351:main] Process 1053257 exits successfully.
ml-512-node-042: [2024-07-08 06:02:13,920] [INFO] [launch.py:351:main] Process 1054919 exits successfully.
ml-512-node-042: [2024-07-08 06:02:13,921] [INFO] [launch.py:351:main] Process 1054918 exits successfully.
ml-512-node-042: [2024-07-08 06:02:13,921] [INFO] [launch.py:351:main] Process 1054916 exits successfully.
ml-512-node-042: [2024-07-08 06:02:13,921] [INFO] [launch.py:351:main] Process 1054914 exits successfully.
ml-512-node-042: [2024-07-08 06:02:13,921] [INFO] [launch.py:351:main] Process 1054920 exits successfully.
ml-512-node-042: [2024-07-08 06:02:13,921] [INFO] [launch.py:351:main] Process 1054915 exits successfully.
ml-512-node-042: [2024-07-08 06:02:13,921] [INFO] [launch.py:351:main] Process 1054913 exits successfully.
ml-512-node-042: [2024-07-08 06:02:13,921] [INFO] [launch.py:351:main] Process 1054917 exits successfully.
ml-512-node-041: [2024-07-08 06:02:13,992] [INFO] [launch.py:351:main] Process 1061392 exits successfully.
ml-512-node-041: [2024-07-08 06:02:13,992] [INFO] [launch.py:351:main] Process 1061393 exits successfully.
ml-512-node-041: [2024-07-08 06:02:13,992] [INFO] [launch.py:351:main] Process 1061391 exits successfully.
ml-512-node-041: [2024-07-08 06:02:13,993] [INFO] [launch.py:351:main] Process 1061389 exits successfully.
ml-512-node-041: [2024-07-08 06:02:13,993] [INFO] [launch.py:351:main] Process 1061395 exits successfully.
ml-512-node-041: [2024-07-08 06:02:13,993] [INFO] [launch.py:351:main] Process 1061390 exits successfully.
ml-512-node-041: [2024-07-08 06:02:13,993] [INFO] [launch.py:351:main] Process 1061388 exits successfully.
ml-512-node-040: [2024-07-08 06:02:14,167] [INFO] [launch.py:351:main] Process 1110529 exits successfully.
ml-512-node-040: [2024-07-08 06:02:14,167] [INFO] [launch.py:351:main] Process 1110531 exits successfully.
ml-512-node-040: [2024-07-08 06:02:14,167] [INFO] [launch.py:351:main] Process 1110530 exits successfully.
ml-512-node-040: [2024-07-08 06:02:14,167] [INFO] [launch.py:351:main] Process 1110526 exits successfully.
ml-512-node-040: [2024-07-08 06:02:14,167] [INFO] [launch.py:351:main] Process 1110527 exits successfully.
ml-512-node-040: [2024-07-08 06:02:14,167] [INFO] [launch.py:351:main] Process 1110525 exits successfully.
ml-512-node-033: [2024-07-08 06:02:14,498] [INFO] [launch.py:351:main] Process 1066001 exits successfully.
ml-512-node-033: [2024-07-08 06:02:14,498] [INFO] [launch.py:351:main] Process 1066008 exits successfully.
ml-512-node-033: [2024-07-08 06:02:14,498] [INFO] [launch.py:351:main] Process 1066004 exits successfully.
ml-512-node-037: [2024-07-08 06:02:14,632] [INFO] [launch.py:351:main] Process 1059858 exits successfully.
ml-512-node-037: [2024-07-08 06:02:14,633] [INFO] [launch.py:351:main] Process 1059857 exits successfully.
ml-512-node-037: [2024-07-08 06:02:14,633] [INFO] [launch.py:351:main] Process 1059855 exits successfully.
ml-512-node-037: [2024-07-08 06:02:14,633] [INFO] [launch.py:351:main] Process 1059853 exits successfully.
ml-512-node-037: [2024-07-08 06:02:14,633] [INFO] [launch.py:351:main] Process 1059859 exits successfully.
ml-512-node-037: [2024-07-08 06:02:14,633] [INFO] [launch.py:351:main] Process 1059852 exits successfully.
ml-512-node-037: [2024-07-08 06:02:14,633] [INFO] [launch.py:351:main] Process 1059856 exits successfully.
ml-512-node-036: [2024-07-08 06:02:14,659] [INFO] [launch.py:351:main] Process 1055805 exits successfully.
ml-512-node-036: [2024-07-08 06:02:14,659] [INFO] [launch.py:351:main] Process 1055807 exits successfully.
ml-512-node-036: [2024-07-08 06:02:14,659] [INFO] [launch.py:351:main] Process 1055806 exits successfully.
ml-512-node-036: [2024-07-08 06:02:14,659] [INFO] [launch.py:351:main] Process 1055808 exits successfully.
ml-512-node-036: [2024-07-08 06:02:14,659] [INFO] [launch.py:351:main] Process 1055803 exits successfully.
ml-512-node-039: [2024-07-08 06:02:14,675] [INFO] [launch.py:351:main] Process 1142679 exits successfully.
ml-512-node-039: [2024-07-08 06:02:14,675] [INFO] [launch.py:351:main] Process 1142675 exits successfully.
ml-512-node-038: [2024-07-08 06:02:14,679] [INFO] [launch.py:351:main] Process 1055370 exits successfully.
ml-512-node-038: [2024-07-08 06:02:14,680] [INFO] [launch.py:351:main] Process 1055367 exits successfully.
ml-512-node-035: [2024-07-08 06:02:14,709] [INFO] [launch.py:351:main] Process 1063315 exits successfully.
ml-512-node-035: [2024-07-08 06:02:14,710] [INFO] [launch.py:351:main] Process 1063316 exits successfully.
ml-512-node-035: [2024-07-08 06:02:14,710] [INFO] [launch.py:351:main] Process 1063317 exits successfully.
ml-512-node-045: [2024-07-08 06:02:14,803] [INFO] [launch.py:351:main] Process 1058674 exits successfully.
ml-512-node-045: [2024-07-08 06:02:14,804] [INFO] [launch.py:351:main] Process 1058672 exits successfully.
ml-512-node-045: [2024-07-08 06:02:14,804] [INFO] [launch.py:351:main] Process 1058676 exits successfully.
ml-512-node-045: [2024-07-08 06:02:14,804] [INFO] [launch.py:351:main] Process 1058678 exits successfully.
ml-512-node-045: [2024-07-08 06:02:14,804] [INFO] [launch.py:351:main] Process 1058677 exits successfully.
ml-512-node-045: [2024-07-08 06:02:14,804] [INFO] [launch.py:351:main] Process 1058675 exits successfully.
ml-512-node-045: [2024-07-08 06:02:14,804] [INFO] [launch.py:351:main] Process 1058679 exits successfully.
ml-512-node-043: [2024-07-08 06:02:14,882] [INFO] [launch.py:351:main] Process 1058745 exits successfully.
ml-512-node-041: [2024-07-08 06:02:14,994] [INFO] [launch.py:351:main] Process 1061394 exits successfully.
ml-512-node-045: [2024-07-08 06:02:15,805] [INFO] [launch.py:351:main] Process 1058673 exits successfully.
